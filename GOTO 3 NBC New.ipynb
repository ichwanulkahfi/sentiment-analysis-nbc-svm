{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F76F_WVE5fo_"
   },
   "source": [
    "# **IMPORT DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2062,
     "status": "ok",
     "timestamp": 1652131214517,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "BN5MAzAN5lXR"
   },
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import nltk.corpus\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import codecs\n",
    "from sklearn import model_selection\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score\n",
    "from sklearn.metrics import f1_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQfuU-Py_zVe"
   },
   "source": [
    "# **NBC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1652131732937,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "YKGWLNvqC-BO"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('goto-clean.xlsx')\n",
    "df=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652131734432,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "EdRk8hZcAO_P"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(cat.split()[0] for cat in df.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1652131738987,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "WImX7CrA_4sl",
    "outputId": "1849bb75-3266-4e8c-aacd-6ec0fe7e96df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamiin</th>\n",
       "      <th>ababil</th>\n",
       "      <th>abalabal</th>\n",
       "      <th>abang</th>\n",
       "      <th>abba</th>\n",
       "      <th>abdl</th>\n",
       "      <th>abimanyu</th>\n",
       "      <th>abin</th>\n",
       "      <th>abis</th>\n",
       "      <th>absen</th>\n",
       "      <th>...</th>\n",
       "      <th>yukbismillah</th>\n",
       "      <th>yunki</th>\n",
       "      <th>yurisdiksi</th>\n",
       "      <th>zazkia</th>\n",
       "      <th>zeebo</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zona</th>\n",
       "      <th>zonk</th>\n",
       "      <th>zuper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5846 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aamiin  ababil  abalabal  abang  abba  abdl  abimanyu  abin  abis  absen  \\\n",
       "0       0       0         0      0     0     0         0     0     0      0   \n",
       "1       0       0         0      0     0     0         0     0     0      0   \n",
       "2       0       0         0      0     0     0         0     0     0      0   \n",
       "3       0       0         0      0     0     0         0     0     0      0   \n",
       "4       0       0         0      0     0     0         0     0     0      0   \n",
       "\n",
       "   ...  yukbismillah  yunki  yurisdiksi  zazkia  zeebo  zero  zeros  zona  \\\n",
       "0  ...             0      0           0       0      0     0      0     0   \n",
       "1  ...             0      0           0       0      0     0      0     0   \n",
       "2  ...             0      0           0       0      0     0      0     0   \n",
       "3  ...             0      0           0       0      0     0      0     0   \n",
       "4  ...             0      0           0       0      0     0      0     0   \n",
       "\n",
       "   zonk  zuper  \n",
       "0     0      0  \n",
       "1     0      0  \n",
       "2     0      0  \n",
       "3     0      0  \n",
       "4     0      0  \n",
       "\n",
       "[5 rows x 5846 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vector = CountVectorizer(min_df=1)\n",
    "df_counted = vector.fit_transform(df[\"tweet\"])\n",
    "df_counted = df_counted.toarray()\n",
    "feature_names = vector.get_feature_names()\n",
    "feature_counted = pd.DataFrame(df_counted, columns = feature_names)\n",
    "feature_counted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 361,
     "status": "ok",
     "timestamp": 1652131743534,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "xtlqvEFyDQ7e",
    "outputId": "d900d249-2be5-4d2b-982c-bbc27b7d4467"
   },
   "outputs": [],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer(use_idf = True)\n",
    "df_tfidf = tfidf_transformer.fit_transform(df_counted)\n",
    "feature_tfidf = pd.DataFrame(df_tfidf.A, columns =\n",
    "vector.get_feature_names())\n",
    "#feature_tfidf.to_excel('tfidf.xlsx')\n",
    "#print(np.shape(feature_tfidf))\n",
    "#feature_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1652131745586,
     "user": {
      "displayName": "Krisna Al Rasyid",
      "userId": "00535902482837260720"
     },
     "user_tz": -420
    },
    "id": "Pjl0U79KDX_B"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [  29   31   39   42   44   49   72   98  113  124  125  130  134  138\n",
      "  142  148  154  158  159  192  202  214  218  241  245  282  291  298\n",
      "  302  304  308  311  314  333  347  348  349  352  376  380  381  394\n",
      "  398  402  405  446  452  453  463  470  483  487  489  491  495  499\n",
      "  500  502  530  531  533  534  541  556  562  567  575  578  582  599\n",
      "  601  608  619  624  636  639  651  661  675  678  704  716  727  731\n",
      "  735  751  771  776  780  806  825  831  866  872  873  878  882  883\n",
      "  896  898  906  910  933  938  939  942  965  976  977  991 1001 1002\n",
      " 1003 1012 1013 1042 1043 1066 1085 1087 1091 1108 1109 1114 1115 1116\n",
      " 1118 1141 1176 1185 1202 1220 1239 1245 1246 1250 1262 1271 1275 1338\n",
      " 1349 1351 1358 1364 1368 1376 1389 1399 1422 1428 1430 1433 1437 1448\n",
      " 1457 1461 1474 1480 1482 1499 1509 1511 1514 1529 1545 1551 1556 1559\n",
      " 1564 1586 1606 1632 1642 1643 1651 1662 1670 1680 1688 1691 1695 1696\n",
      " 1702 1721 1742 1746 1749 1752 1760 1763 1772 1778 1783 1784 1793 1803\n",
      " 1819 1824 1855 1861 1865 1867 1869 1877 1891 1892 1894 1906 1916 1951\n",
      " 1953 1958 1969 1995 2006 2013 2017 2047 2066 2070 2081 2087 2091 2100\n",
      " 2103 2104 2106 2111 2160 2164 2165 2166 2175 2189 2200 2216 2250 2299\n",
      " 2311 2324 2332 2337 2345 2346 2351 2373 2381 2383 2384 2385 2394 2396\n",
      " 2423 2445 2447 2448 2450 2451 2459 2466 2493 2505 2518 2526 2533 2552\n",
      " 2585 2591 2612 2626 2635 2648 2651 2661 2669 2689 2692 2707 2708 2720\n",
      " 2728 2747 2752 2764 2772 2781 2790 2797 2802 2810 2814 2838 2855 2857\n",
      " 2869 2878 2905 2913 2920 2924 2952 2954 2964 2969 2982 3008 3010 3022\n",
      " 3031 3034 3035 3053 3054 3119 3133 3138 3160 3173 3188 3209 3238 3243\n",
      " 3254 3256 3258 3269 3275 3286 3288 3294 3302 3305 3317 3318 3332 3354\n",
      " 3355 3360 3375 3377 3386 3411 3414 3422 3461 3475 3480 3489 3491 3530\n",
      " 3538 3552 3554 3556 3561 3577 3581 3585 3587 3592 3595 3606 3638 3640\n",
      " 3649 3654 3714 3726 3736 3746 3760 3767 3771 3790 3807 3817 3826 3840\n",
      " 3844 3857 3862 3866 3867 3882 3901 3909 3934 3940 3946 3967 3970 3974\n",
      " 3979 3985 4000 4005 4007 4013 4019 4025 4037 4042 4070 4085 4095 4102\n",
      " 4105 4121 4127 4138 4149 4152 4160 4169 4174 4176 4195 4207 4213 4225\n",
      " 4234 4238 4246 4249 4251 4253 4266 4276 4299 4307 4308 4314 4318 4335\n",
      " 4345 4349 4351 4361 4397 4409 4425 4443 4449 4451 4457 4480 4481 4491\n",
      " 4520 4531 4532 4533 4547 4548 4549 4555 4561 4563 4590 4594 4610 4622\n",
      " 4645 4646 4654 4660 4668 4670 4688 4690 4694 4705 4714 4725 4729 4736\n",
      " 4738 4766 4775 4788 4789 4808 4820 4822 4831 4839 4849 4879 4881 4904\n",
      " 4905 4926 4932 4937 4943]\n",
      "[array([[0.50623079, 0.49376921],\n",
      "       [0.14088191, 0.85911809],\n",
      "       [0.33515864, 0.66484136],\n",
      "       ...,\n",
      "       [0.77669033, 0.22330967],\n",
      "       [0.17099512, 0.82900488],\n",
      "       [0.85596178, 0.14403822]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89      1842\n",
      "           1       0.91      0.96      0.93      2613\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.65%\n",
      "AUC Train:  0.9079131403867656\n",
      "CM Train = \n",
      "[[1581  261]\n",
      " [ 111 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77       201\n",
      "           1       0.82      0.91      0.86       294\n",
      "\n",
      "    accuracy                           0.83       495\n",
      "   macro avg       0.83      0.81      0.82       495\n",
      "weighted avg       0.83      0.83      0.83       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 83.03%\n",
      "AUC Test:  0.8115037059599959\n",
      "CM Test = \n",
      "[[143  58]\n",
      " [ 26 268]]\n",
      "--------------------------------------------------------\n",
      "Fold  2\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   9   12   22   30   33   34   45   57   70   87   95  104  117  122\n",
      "  135  156  161  162  167  170  173  189  195  217  220  223  224  246\n",
      "  252  253  263  269  271  294  326  378  379  383  396  406  410  415\n",
      "  472  481  496  507  514  517  520  521  526  528  538  543  545  548\n",
      "  559  584  628  629  630  634  641  660  666  668  684  720  728  773\n",
      "  775  788  799  812  817  829  842  843  844  847  849  852  854  861\n",
      "  862  864  867  871  888  891  895  918  949  962  971  979 1005 1011\n",
      " 1014 1022 1051 1065 1069 1082 1084 1098 1104 1119 1122 1139 1160 1161\n",
      " 1172 1177 1203 1224 1237 1256 1259 1261 1272 1277 1281 1290 1299 1319\n",
      " 1326 1327 1328 1329 1330 1332 1343 1362 1367 1380 1385 1387 1391 1393\n",
      " 1411 1412 1418 1419 1420 1423 1431 1450 1460 1475 1478 1487 1495 1497\n",
      " 1507 1515 1522 1525 1526 1531 1533 1536 1547 1563 1567 1580 1581 1590\n",
      " 1615 1620 1625 1652 1658 1675 1687 1692 1697 1700 1726 1741 1755 1765\n",
      " 1767 1774 1790 1791 1794 1834 1836 1872 1879 1888 1902 1926 1934 1939\n",
      " 1940 1965 1982 1986 1990 1996 1999 2012 2030 2033 2038 2048 2058 2063\n",
      " 2071 2075 2118 2124 2137 2150 2154 2171 2177 2201 2203 2212 2215 2219\n",
      " 2223 2231 2239 2260 2265 2290 2308 2315 2323 2339 2399 2401 2421 2436\n",
      " 2452 2455 2475 2478 2487 2491 2498 2500 2509 2527 2528 2539 2553 2579\n",
      " 2611 2617 2618 2619 2639 2650 2670 2672 2693 2700 2701 2706 2714 2719\n",
      " 2730 2734 2740 2744 2770 2779 2795 2817 2818 2829 2831 2832 2841 2846\n",
      " 2849 2864 2865 2872 2876 2882 2888 2899 2911 2915 2917 2933 2943 2949\n",
      " 2958 2959 2971 2981 2983 2992 3006 3011 3039 3040 3046 3068 3083 3086\n",
      " 3124 3127 3149 3162 3169 3196 3210 3212 3217 3220 3234 3244 3255 3260\n",
      " 3270 3276 3287 3289 3303 3343 3348 3371 3373 3408 3447 3452 3471 3473\n",
      " 3474 3503 3506 3508 3512 3514 3515 3524 3536 3539 3542 3546 3563 3567\n",
      " 3568 3575 3578 3579 3589 3601 3609 3615 3616 3617 3626 3644 3647 3658\n",
      " 3669 3670 3679 3680 3687 3698 3703 3704 3705 3709 3710 3712 3766 3772\n",
      " 3773 3776 3785 3786 3791 3805 3824 3853 3855 3859 3861 3880 3884 3890\n",
      " 3891 3899 3908 3913 3933 3948 3964 3984 3986 3994 3996 4001 4004 4010\n",
      " 4021 4023 4028 4030 4036 4041 4056 4062 4068 4069 4080 4083 4104 4112\n",
      " 4113 4123 4124 4130 4136 4154 4155 4158 4190 4237 4243 4252 4270 4311\n",
      " 4336 4338 4371 4391 4406 4422 4424 4440 4467 4473 4475 4497 4513 4519\n",
      " 4535 4537 4540 4541 4543 4556 4558 4572 4576 4581 4587 4589 4593 4601\n",
      " 4615 4618 4634 4637 4649 4659 4667 4689 4702 4724 4742 4747 4753 4758\n",
      " 4784 4793 4794 4814 4821 4829 4847 4861 4873 4880 4883 4885 4888 4892\n",
      " 4901 4903 4910 4912 4939]\n",
      "[array([[0.5506611 , 0.4493389 ],\n",
      "       [0.11631439, 0.88368561],\n",
      "       [0.33541877, 0.66458123],\n",
      "       ...,\n",
      "       [0.77944765, 0.22055235],\n",
      "       [0.22249598, 0.77750402],\n",
      "       [0.80876657, 0.19123343]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1846\n",
      "           1       0.90      0.96      0.93      2609\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.67%\n",
      "AUC Train:  0.9079881001965444\n",
      "CM Train = \n",
      "[[1582  264]\n",
      " [ 107 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       197\n",
      "           1       0.85      0.90      0.88       298\n",
      "\n",
      "    accuracy                           0.85       495\n",
      "   macro avg       0.85      0.83      0.84       495\n",
      "weighted avg       0.85      0.85      0.85       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 84.85%\n",
      "AUC Test:  0.8345910128436616\n",
      "CM Test = \n",
      "[[151  46]\n",
      " [ 29 269]]\n",
      "--------------------------------------------------------\n",
      "Fold  3\n",
      "TRAIN : [   0    2    3 ... 4947 4948 4949] TEST : [   1   23   36   37   53   61   85   88  182  185  203  206  221  227\n",
      "  230  248  276  283  286  289  295  325  345  382  384  408  429  457\n",
      "  462  465  467  480  482  485  501  516  527  536  546  553  555  569\n",
      "  576  581  613  615  620  621  622  638  648  663  667  680  683  685\n",
      "  687  690  692  706  708  712  748  768  787  794  803  809  836  841\n",
      "  857  900  917  925  927  980  982  985  995 1009 1021 1046 1047 1068\n",
      " 1073 1077 1095 1127 1163 1170 1196 1223 1230 1232 1248 1267 1273 1280\n",
      " 1288 1298 1303 1309 1324 1357 1359 1363 1366 1370 1371 1377 1379 1390\n",
      " 1410 1414 1432 1441 1452 1465 1470 1471 1489 1490 1491 1505 1521 1523\n",
      " 1530 1540 1544 1569 1596 1654 1657 1666 1669 1698 1705 1706 1712 1715\n",
      " 1718 1722 1736 1738 1750 1754 1757 1759 1761 1766 1789 1804 1813 1814\n",
      " 1815 1828 1835 1850 1852 1870 1887 1889 1900 1907 1922 1928 1933 1957\n",
      " 1960 1972 1974 1989 1991 1992 2009 2011 2027 2034 2044 2052 2062 2065\n",
      " 2067 2069 2072 2078 2088 2102 2108 2112 2125 2149 2152 2162 2184 2188\n",
      " 2193 2194 2196 2204 2214 2217 2232 2240 2243 2255 2263 2270 2272 2275\n",
      " 2277 2284 2285 2301 2303 2307 2318 2327 2340 2355 2358 2359 2367 2370\n",
      " 2374 2382 2404 2433 2440 2460 2473 2481 2483 2494 2513 2531 2534 2571\n",
      " 2574 2586 2594 2602 2605 2606 2620 2644 2647 2649 2658 2663 2664 2676\n",
      " 2678 2686 2717 2729 2753 2769 2771 2803 2807 2828 2839 2858 2868 2886\n",
      " 2889 2901 2906 2922 2931 2938 2939 2951 2967 2974 2975 2976 2985 2996\n",
      " 3001 3005 3014 3021 3025 3037 3044 3045 3051 3058 3059 3061 3063 3072\n",
      " 3073 3076 3079 3090 3095 3097 3110 3120 3122 3131 3144 3145 3151 3152\n",
      " 3154 3156 3161 3174 3183 3184 3197 3200 3201 3202 3213 3225 3228 3233\n",
      " 3245 3262 3284 3297 3301 3312 3315 3327 3328 3334 3340 3349 3350 3351\n",
      " 3353 3368 3382 3389 3397 3425 3426 3427 3439 3456 3472 3477 3484 3488\n",
      " 3497 3498 3504 3518 3522 3529 3532 3558 3565 3569 3594 3597 3600 3602\n",
      " 3625 3630 3631 3636 3646 3651 3662 3664 3671 3677 3684 3707 3713 3741\n",
      " 3754 3755 3763 3774 3798 3804 3809 3819 3873 3881 3907 3911 3916 3930\n",
      " 3959 3977 3987 4002 4046 4050 4088 4092 4096 4098 4106 4115 4118 4120\n",
      " 4131 4133 4137 4140 4146 4151 4161 4167 4171 4172 4183 4200 4208 4216\n",
      " 4217 4228 4233 4244 4245 4264 4267 4274 4277 4279 4284 4293 4295 4300\n",
      " 4315 4316 4322 4323 4334 4337 4347 4348 4357 4362 4363 4364 4365 4368\n",
      " 4372 4380 4392 4399 4418 4426 4434 4446 4453 4474 4486 4487 4495 4500\n",
      " 4505 4527 4528 4534 4554 4564 4585 4588 4598 4628 4640 4641 4658 4669\n",
      " 4704 4712 4734 4741 4749 4756 4771 4773 4790 4797 4799 4806 4817 4844\n",
      " 4862 4902 4913 4929 4930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.51369864, 0.48630136],\n",
      "       [0.33612251, 0.66387749],\n",
      "       [0.6454615 , 0.3545385 ],\n",
      "       ...,\n",
      "       [0.78194134, 0.21805866],\n",
      "       [0.19591561, 0.80408439],\n",
      "       [0.84940272, 0.15059728]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1851\n",
      "           1       0.91      0.96      0.93      2604\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.92      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 92.01%\n",
      "AUC Train:  0.9118812971939442\n",
      "CM Train = \n",
      "[[1598  253]\n",
      " [ 103 2501]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       192\n",
      "           1       0.81      0.89      0.85       303\n",
      "\n",
      "    accuracy                           0.80       495\n",
      "   macro avg       0.80      0.78      0.79       495\n",
      "weighted avg       0.80      0.80      0.80       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 80.40%\n",
      "AUC Test:  0.778877887788779\n",
      "CM Test = \n",
      "[[128  64]\n",
      " [ 33 270]]\n",
      "--------------------------------------------------------\n",
      "Fold  4\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   3    4   10   14   15   17   50   64   66   71   86   92   97  109\n",
      "  118  132  133  137  144  149  169  177  188  190  191  196  200  219\n",
      "  226  229  234  242  244  249  257  261  285  288  290  296  299  305\n",
      "  306  316  317  321  322  332  338  346  368  386  388  389  390  399\n",
      "  409  418  421  422  426  436  440  443  444  451  461  473  509  535\n",
      "  558  565  566  570  572  579  587  589  590  596  598  607  616  635\n",
      "  643  654  682  688  695  725  729  743  749  758  832  834  835  840\n",
      "  868  879  880  897  899  905  914  929  934  935  944  951  953  958\n",
      "  959  961  983  988  989  996  998 1018 1034 1056 1059 1062 1070 1093\n",
      " 1120 1129 1144 1148 1150 1174 1180 1182 1183 1190 1191 1197 1206 1240\n",
      " 1242 1266 1269 1276 1282 1283 1284 1285 1287 1292 1300 1334 1336 1342\n",
      " 1373 1382 1386 1404 1427 1436 1445 1458 1464 1473 1494 1496 1503 1504\n",
      " 1513 1519 1542 1566 1571 1573 1574 1577 1593 1601 1621 1640 1644 1649\n",
      " 1667 1708 1744 1768 1770 1771 1800 1812 1826 1829 1830 1831 1837 1839\n",
      " 1853 1875 1881 1895 1931 1936 1941 1949 1961 1977 1979 1997 2016 2024\n",
      " 2036 2049 2060 2076 2089 2140 2148 2172 2211 2224 2234 2242 2244 2247\n",
      " 2278 2293 2294 2300 2306 2338 2347 2368 2377 2379 2397 2406 2425 2443\n",
      " 2464 2465 2470 2471 2477 2484 2490 2497 2501 2510 2519 2525 2530 2540\n",
      " 2543 2549 2566 2575 2577 2580 2601 2604 2616 2625 2630 2631 2640 2645\n",
      " 2655 2657 2667 2682 2696 2702 2703 2722 2724 2727 2736 2749 2755 2784\n",
      " 2794 2796 2804 2806 2812 2815 2816 2823 2825 2826 2830 2842 2843 2854\n",
      " 2885 2898 2921 2940 2994 3007 3012 3019 3027 3029 3036 3041 3050 3052\n",
      " 3055 3060 3065 3077 3080 3088 3098 3100 3111 3132 3139 3170 3179 3226\n",
      " 3229 3231 3236 3240 3253 3263 3274 3307 3311 3320 3322 3324 3338 3346\n",
      " 3390 3391 3392 3400 3410 3412 3429 3431 3432 3435 3440 3449 3453 3460\n",
      " 3493 3495 3520 3521 3535 3537 3550 3553 3564 3571 3583 3586 3598 3633\n",
      " 3655 3660 3663 3666 3672 3673 3682 3706 3732 3733 3740 3764 3783 3803\n",
      " 3822 3828 3838 3842 3843 3848 3849 3887 3889 3892 3895 3897 3900 3924\n",
      " 3932 3953 3957 3992 4003 4027 4031 4035 4044 4053 4079 4107 4109 4111\n",
      " 4114 4125 4134 4139 4141 4156 4173 4175 4178 4194 4209 4222 4235 4239\n",
      " 4240 4248 4254 4269 4298 4302 4304 4312 4340 4341 4385 4388 4394 4396\n",
      " 4400 4408 4412 4413 4432 4438 4462 4463 4466 4471 4478 4482 4488 4507\n",
      " 4512 4514 4544 4546 4560 4568 4570 4579 4623 4650 4657 4661 4663 4678\n",
      " 4681 4682 4685 4686 4706 4707 4722 4727 4731 4739 4757 4762 4769 4772\n",
      " 4776 4785 4796 4802 4811 4816 4826 4833 4834 4835 4841 4853 4868 4875\n",
      " 4877 4886 4911 4923 4934]\n",
      "[array([[0.47734796, 0.52265204],\n",
      "       [0.13624329, 0.86375671],\n",
      "       [0.33597894, 0.66402106],\n",
      "       ...,\n",
      "       [0.76488418, 0.23511582],\n",
      "       [0.19619367, 0.80380633],\n",
      "       [0.84661438, 0.15338562]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1844\n",
      "           1       0.91      0.96      0.93      2611\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.83%\n",
      "AUC Train:  0.9099836043237729\n",
      "CM Train = \n",
      "[[1589  255]\n",
      " [ 109 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       199\n",
      "           1       0.81      0.90      0.85       296\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.82      0.80      0.80       495\n",
      "weighted avg       0.82      0.82      0.81       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 81.62%\n",
      "AUC Test:  0.7960579926660329\n",
      "CM Test = \n",
      "[[138  61]\n",
      " [ 30 266]]\n",
      "--------------------------------------------------------\n",
      "Fold  5\n",
      "TRAIN : [   0    1    3 ... 4947 4948 4949] TEST : [   2    5   40   51   68   69   76   82  105  121  141  163  175  176\n",
      "  179  204  211  228  232  235  238  240  259  264  272  277  297  300\n",
      "  313  320  323  330  351  353  356  361  365  366  369  385  411  413\n",
      "  414  419  425  427  454  458  488  493  503  515  519  529  547  564\n",
      "  574  600  618  652  655  657  670  674  677  681  686  694  701  702\n",
      "  703  710  711  713  719  722  744  745  746  764  778  779  783  786\n",
      "  791  793  796  800  805  826  838  846  850  853  856  874  890  923\n",
      "  924  936  937  940  943  954  955  963  964  972  975  981  984  999\n",
      " 1015 1023 1032 1036 1037 1038 1044 1048 1052 1058 1074 1078 1079 1081\n",
      " 1094 1100 1101 1110 1112 1128 1137 1140 1149 1151 1157 1171 1184 1194\n",
      " 1195 1199 1214 1225 1235 1236 1254 1255 1268 1270 1310 1311 1313 1317\n",
      " 1318 1341 1347 1355 1388 1395 1397 1425 1446 1451 1462 1493 1501 1535\n",
      " 1548 1553 1554 1555 1560 1572 1583 1600 1602 1607 1618 1646 1647 1656\n",
      " 1660 1693 1699 1703 1710 1713 1719 1728 1732 1733 1739 1751 1762 1764\n",
      " 1775 1798 1811 1818 1825 1832 1856 1860 1878 1886 1898 1899 1911 1912\n",
      " 1914 1917 1921 1927 1943 1945 1947 1948 1952 1955 1994 2000 2004 2010\n",
      " 2019 2031 2039 2041 2042 2057 2085 2092 2094 2101 2110 2117 2131 2134\n",
      " 2139 2141 2143 2146 2155 2157 2161 2169 2174 2178 2183 2185 2228 2230\n",
      " 2254 2258 2281 2287 2310 2329 2343 2350 2357 2361 2364 2365 2369 2372\n",
      " 2378 2400 2407 2409 2412 2417 2439 2453 2457 2472 2480 2507 2517 2523\n",
      " 2537 2542 2545 2550 2565 2578 2590 2592 2600 2608 2666 2709 2718 2731\n",
      " 2758 2760 2762 2768 2776 2782 2788 2791 2793 2799 2808 2840 2848 2863\n",
      " 2866 2873 2879 2884 2892 2900 2902 2916 2923 2928 2942 2947 2948 2953\n",
      " 2961 2962 2966 2986 2998 3030 3038 3043 3082 3126 3129 3135 3171 3172\n",
      " 3180 3195 3199 3227 3239 3265 3304 3314 3335 3339 3341 3352 3362 3374\n",
      " 3380 3381 3403 3417 3433 3434 3442 3443 3448 3450 3457 3462 3464 3469\n",
      " 3502 3509 3528 3548 3559 3570 3573 3574 3580 3618 3634 3637 3652 3653\n",
      " 3675 3688 3691 3700 3701 3722 3731 3735 3757 3770 3777 3780 3784 3795\n",
      " 3814 3815 3839 3847 3858 3865 3883 3885 3903 3904 3921 3935 3956 3965\n",
      " 3982 4017 4058 4059 4064 4074 4086 4110 4135 4165 4199 4202 4205 4206\n",
      " 4211 4221 4229 4247 4250 4257 4261 4265 4268 4282 4286 4288 4291 4296\n",
      " 4321 4330 4339 4354 4379 4382 4414 4439 4448 4459 4489 4490 4493 4498\n",
      " 4502 4509 4511 4522 4552 4583 4595 4600 4614 4616 4619 4625 4626 4631\n",
      " 4633 4635 4638 4644 4695 4696 4709 4720 4726 4728 4745 4750 4751 4755\n",
      " 4768 4781 4782 4795 4812 4819 4823 4836 4843 4848 4852 4869 4889 4890\n",
      " 4894 4895 4898 4909 4940]\n",
      "[array([[0.54660428, 0.45339572],\n",
      "       [0.10559595, 0.89440405],\n",
      "       [0.65813218, 0.34186782],\n",
      "       ...,\n",
      "       [0.75886495, 0.24113505],\n",
      "       [0.19585331, 0.80414669],\n",
      "       [0.86278398, 0.13721602]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1835\n",
      "           1       0.90      0.96      0.93      2620\n",
      "\n",
      "    accuracy                           0.91      4455\n",
      "   macro avg       0.92      0.90      0.91      4455\n",
      "weighted avg       0.92      0.91      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.38%\n",
      "AUC Train:  0.9040216735653223\n",
      "CM Train = \n",
      "[[1557  278]\n",
      " [ 106 2514]]\n",
      "----- Evaluation on Test Data -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73       208\n",
      "           1       0.79      0.88      0.83       287\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.80      0.78      0.78       495\n",
      "weighted avg       0.79      0.79      0.79       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 79.39%\n",
      "AUC Test:  0.7779666979362101\n",
      "CM Test = \n",
      "[[141  67]\n",
      " [ 35 252]]\n",
      "--------------------------------------------------------\n",
      "Fold  6\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   6    8   11   13   18   20   26   27   41   47   48   52   58   59\n",
      "   67   80   84   90  107  108  119  145  157  187  194  215  251  254\n",
      "  268  274  278  303  315  318  328  331  340  344  357  359  360  391\n",
      "  392  393  438  439  442  455  456  459  468  474  476  477  478  486\n",
      "  505  518  522  557  563  568  585  588  597  602  603  609  610  646\n",
      "  653  669  672  676  689  700  715  717  723  752  757  762  766  772\n",
      "  774  781  784  789  795  813  819  820  855  859  865  886  909  912\n",
      "  913  919  921  926  932  966  969  993  997 1017 1025 1027 1035 1041\n",
      " 1049 1055 1061 1063 1083 1086 1099 1103 1106 1117 1136 1138 1147 1158\n",
      " 1168 1173 1187 1210 1212 1213 1215 1217 1222 1231 1238 1244 1264 1278\n",
      " 1293 1296 1315 1346 1352 1354 1372 1374 1396 1403 1424 1426 1444 1449\n",
      " 1454 1463 1467 1476 1477 1485 1549 1550 1587 1592 1599 1603 1604 1609\n",
      " 1610 1612 1626 1633 1636 1648 1663 1673 1686 1694 1714 1717 1723 1724\n",
      " 1727 1735 1737 1748 1756 1780 1785 1806 1808 1810 1846 1854 1897 1905\n",
      " 1915 1918 1920 1923 1929 1930 1944 1950 1959 1962 1976 1978 1980 1983\n",
      " 2005 2025 2054 2074 2080 2095 2096 2115 2123 2126 2142 2145 2151 2180\n",
      " 2181 2192 2198 2205 2210 2226 2248 2252 2268 2271 2280 2312 2319 2331\n",
      " 2334 2362 2411 2415 2420 2427 2432 2438 2462 2476 2485 2486 2488 2535\n",
      " 2551 2554 2556 2558 2560 2570 2573 2584 2587 2613 2615 2621 2623 2627\n",
      " 2629 2636 2673 2688 2694 2713 2715 2735 2741 2743 2748 2751 2756 2759\n",
      " 2761 2777 2778 2805 2824 2835 2856 2875 2877 2895 2907 2909 2926 2929\n",
      " 2944 2946 2955 2972 2980 2984 3002 3009 3016 3023 3048 3056 3066 3067\n",
      " 3071 3074 3075 3081 3099 3103 3104 3108 3118 3140 3141 3150 3157 3166\n",
      " 3175 3177 3206 3207 3214 3222 3235 3237 3241 3251 3278 3281 3319 3321\n",
      " 3323 3325 3357 3359 3364 3365 3369 3376 3385 3405 3438 3446 3482 3487\n",
      " 3499 3500 3501 3507 3517 3526 3540 3551 3572 3603 3619 3628 3635 3639\n",
      " 3681 3693 3699 3739 3743 3744 3753 3756 3758 3761 3789 3810 3820 3827\n",
      " 3830 3831 3832 3836 3845 3852 3856 3863 3864 3872 3876 3878 3917 3927\n",
      " 3937 3941 3954 3960 3976 3978 3981 3989 3991 3993 4008 4012 4015 4016\n",
      " 4018 4020 4022 4029 4032 4033 4034 4054 4061 4067 4073 4077 4081 4082\n",
      " 4090 4129 4143 4148 4153 4166 4181 4188 4193 4196 4198 4219 4223 4231\n",
      " 4255 4271 4273 4283 4287 4327 4346 4350 4389 4405 4411 4431 4433 4435\n",
      " 4477 4483 4506 4523 4526 4569 4592 4607 4611 4612 4617 4630 4632 4643\n",
      " 4647 4648 4653 4655 4662 4666 4673 4691 4692 4693 4717 4719 4732 4754\n",
      " 4764 4770 4800 4801 4815 4824 4838 4842 4845 4854 4866 4874 4876 4878\n",
      " 4896 4914 4917 4945 4946]\n",
      "[array([[0.48175447, 0.51824553],\n",
      "       [0.12584119, 0.87415881],\n",
      "       [0.26109758, 0.73890242],\n",
      "       ...,\n",
      "       [0.76456192, 0.23543808],\n",
      "       [0.23308654, 0.76691346],\n",
      "       [0.83777258, 0.16222742]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1832\n",
      "           1       0.91      0.96      0.93      2623\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.81%\n",
      "AUC Train:  0.9091886602726637\n",
      "CM Train = \n",
      "[[1574  258]\n",
      " [ 107 2516]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74       211\n",
      "           1       0.78      0.92      0.84       284\n",
      "\n",
      "    accuracy                           0.80       495\n",
      "   macro avg       0.82      0.78      0.79       495\n",
      "weighted avg       0.81      0.80      0.80       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 80.20%\n",
      "AUC Test:  0.7817819237701088\n",
      "CM Test = \n",
      "[[136  75]\n",
      " [ 23 261]]\n",
      "--------------------------------------------------------\n",
      "Fold  7\n",
      "TRAIN : [   0    1    2 ... 4946 4947 4948] TEST : [  19   43   46   54   55   77   91  101  102  106  111  128  139  140\n",
      "  147  152  166  198  208  233  250  255  260  262  267  270  279  287\n",
      "  301  309  310  312  327  335  342  354  407  431  441  466  475  490\n",
      "  492  506  511  512  513  532  551  583  593  594  633  642  665  718\n",
      "  721  724  733  750  767  792  810  815  818  822  828  876  884  892\n",
      "  893  904  907  915  916  930  946  950  970  986  987  990 1000 1007\n",
      " 1010 1019 1029 1030 1039 1045 1054 1067 1088 1096 1097 1105 1126 1142\n",
      " 1145 1155 1165 1175 1188 1192 1193 1205 1211 1226 1247 1251 1252 1257\n",
      " 1258 1260 1263 1279 1286 1301 1302 1304 1314 1316 1322 1323 1335 1339\n",
      " 1345 1350 1369 1375 1381 1394 1416 1417 1453 1455 1486 1512 1524 1537\n",
      " 1538 1539 1541 1543 1557 1568 1570 1578 1588 1611 1617 1627 1628 1637\n",
      " 1639 1665 1677 1678 1679 1683 1709 1716 1725 1743 1753 1758 1773 1779\n",
      " 1786 1801 1817 1822 1827 1840 1841 1844 1845 1857 1859 1866 1880 1883\n",
      " 1884 1885 1901 1925 1942 1964 1966 1981 1993 2001 2014 2029 2037 2043\n",
      " 2053 2055 2064 2073 2079 2082 2084 2090 2109 2114 2128 2130 2132 2133\n",
      " 2144 2147 2158 2170 2190 2209 2213 2220 2233 2235 2241 2249 2288 2295\n",
      " 2297 2298 2302 2313 2326 2330 2342 2348 2390 2393 2403 2408 2410 2413\n",
      " 2416 2419 2424 2429 2430 2434 2441 2461 2468 2482 2506 2516 2521 2522\n",
      " 2559 2563 2564 2567 2569 2572 2583 2588 2597 2622 2628 2632 2642 2653\n",
      " 2662 2668 2674 2675 2677 2697 2699 2704 2705 2738 2774 2783 2801 2833\n",
      " 2837 2847 2853 2859 2871 2880 2887 2890 2891 2894 2896 2912 2918 2935\n",
      " 2941 2945 2950 2968 2970 2979 3000 3015 3028 3033 3064 3084 3089 3093\n",
      " 3106 3121 3130 3136 3147 3155 3158 3164 3167 3185 3194 3198 3211 3218\n",
      " 3223 3247 3249 3259 3261 3266 3282 3283 3295 3309 3326 3333 3342 3378\n",
      " 3379 3394 3407 3416 3420 3424 3428 3459 3479 3481 3490 3496 3519 3534\n",
      " 3562 3576 3582 3584 3588 3610 3621 3624 3629 3643 3648 3650 3659 3667\n",
      " 3668 3689 3694 3697 3711 3720 3723 3725 3738 3750 3759 3768 3787 3788\n",
      " 3801 3816 3823 3837 3869 3871 3879 3888 3894 3896 3902 3905 3906 3915\n",
      " 3919 3923 3925 3936 3939 3947 3961 3963 3972 3975 3983 3998 4014 4024\n",
      " 4049 4055 4065 4072 4084 4093 4100 4116 4132 4144 4145 4157 4159 4164\n",
      " 4179 4210 4227 4241 4281 4285 4290 4292 4294 4303 4309 4310 4319 4324\n",
      " 4328 4343 4355 4366 4367 4383 4398 4404 4429 4436 4441 4445 4450 4456\n",
      " 4458 4470 4492 4510 4517 4521 4530 4536 4539 4550 4551 4567 4571 4574\n",
      " 4575 4580 4582 4584 4586 4604 4608 4620 4621 4642 4679 4683 4716 4723\n",
      " 4748 4759 4765 4767 4778 4780 4787 4798 4807 4840 4850 4858 4863 4872\n",
      " 4916 4920 4925 4938 4949]\n",
      "[array([[0.50393175, 0.49606825],\n",
      "       [0.10893937, 0.89106063],\n",
      "       [0.33565396, 0.66434604],\n",
      "       ...,\n",
      "       [0.41167228, 0.58832772],\n",
      "       [0.76315535, 0.23684465],\n",
      "       [0.19647226, 0.80352774]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      1834\n",
      "           1       0.90      0.96      0.93      2621\n",
      "\n",
      "    accuracy                           0.91      4455\n",
      "   macro avg       0.92      0.90      0.91      4455\n",
      "weighted avg       0.91      0.91      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.36%\n",
      "AUC Train:  0.9039610444455631\n",
      "CM Train = \n",
      "[[1558  276]\n",
      " [ 109 2512]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77       209\n",
      "           1       0.80      0.92      0.86       286\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.83      0.80      0.81       495\n",
      "weighted avg       0.83      0.82      0.82       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 82.22%\n",
      "AUC Test:  0.8042878174457122\n",
      "CM Test = \n",
      "[[144  65]\n",
      " [ 23 263]]\n",
      "--------------------------------------------------------\n",
      "Fold  8\n",
      "TRAIN : [   0    1    2 ... 4946 4947 4949] TEST : [  16   35   38   56   60   65   73   81   89   96  114  129  143  155\n",
      "  171  172  178  184  193  205  210  231  239  258  265  273  293  319\n",
      "  336  339  341  355  358  362  364  367  370  371  372  374  377  412\n",
      "  416  420  428  432  434  435  479  484  494  498  524  539  542  549\n",
      "  552  554  561  580  631  632  640  644  649  658  679  693  707  726\n",
      "  734  737  740  754  759  760  763  769  782  785  801  811  814  823\n",
      "  839  863  870  875  877  881  887  889  948  957  960  974  978  992\n",
      "  994 1008 1016 1026 1050 1057 1060 1076 1080 1089 1113 1121 1123 1132\n",
      " 1135 1143 1146 1154 1156 1164 1166 1181 1200 1216 1228 1229 1234 1249\n",
      " 1265 1274 1294 1295 1306 1325 1333 1340 1356 1361 1378 1398 1401 1405\n",
      " 1406 1413 1421 1435 1439 1456 1459 1466 1484 1492 1506 1516 1518 1520\n",
      " 1528 1534 1558 1565 1575 1579 1585 1591 1594 1597 1598 1619 1624 1635\n",
      " 1650 1661 1664 1668 1676 1682 1689 1730 1788 1802 1816 1820 1843 1848\n",
      " 1851 1858 1864 1876 1893 1903 1935 1968 1985 1988 1998 2007 2018 2020\n",
      " 2026 2028 2035 2050 2061 2077 2083 2086 2093 2099 2113 2116 2119 2136\n",
      " 2156 2168 2191 2202 2207 2208 2218 2225 2229 2238 2245 2246 2256 2259\n",
      " 2262 2266 2267 2279 2289 2291 2305 2316 2320 2325 2328 2336 2356 2360\n",
      " 2363 2366 2388 2395 2398 2402 2426 2449 2454 2456 2504 2512 2514 2515\n",
      " 2529 2548 2557 2561 2568 2582 2596 2624 2637 2638 2641 2643 2654 2656\n",
      " 2680 2690 2698 2725 2737 2746 2754 2765 2773 2780 2785 2792 2821 2834\n",
      " 2836 2844 2851 2861 2862 2883 2910 2914 2925 2932 2936 2973 2978 2988\n",
      " 2990 2993 3003 3004 3013 3018 3020 3032 3042 3049 3069 3094 3101 3112\n",
      " 3117 3159 3168 3176 3178 3181 3182 3192 3193 3203 3242 3248 3250 3257\n",
      " 3296 3300 3313 3344 3345 3347 3358 3363 3367 3370 3387 3401 3402 3406\n",
      " 3409 3415 3423 3436 3470 3476 3483 3492 3494 3523 3527 3541 3544 3545\n",
      " 3555 3566 3599 3605 3607 3608 3613 3614 3620 3627 3645 3656 3683 3690\n",
      " 3692 3696 3708 3719 3721 3724 3727 3737 3742 3769 3775 3779 3782 3812\n",
      " 3813 3818 3829 3833 3834 3835 3846 3850 3870 3875 3910 3914 3920 3926\n",
      " 3931 3938 3943 3944 3949 3950 3951 3955 3990 4026 4048 4052 4063 4097\n",
      " 4117 4119 4128 4150 4168 4170 4177 4184 4197 4203 4215 4220 4224 4236\n",
      " 4256 4275 4280 4306 4320 4325 4326 4329 4331 4344 4352 4356 4358 4359\n",
      " 4386 4395 4401 4410 4415 4416 4427 4428 4437 4442 4447 4452 4454 4465\n",
      " 4472 4476 4494 4501 4538 4542 4545 4553 4559 4565 4602 4603 4609 4613\n",
      " 4624 4629 4639 4664 4674 4676 4700 4701 4721 4730 4743 4760 4761 4774\n",
      " 4779 4791 4792 4803 4810 4825 4832 4846 4856 4860 4882 4884 4891 4899\n",
      " 4906 4922 4933 4942 4948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.51614922, 0.48385078],\n",
      "       [0.12754836, 0.87245164],\n",
      "       [0.33561433, 0.66438567],\n",
      "       ...,\n",
      "       [0.41391695, 0.58608305],\n",
      "       [0.75080344, 0.24919656],\n",
      "       [0.87794507, 0.12205493]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1844\n",
      "           1       0.90      0.96      0.93      2611\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.56%\n",
      "AUC Train:  0.9064908517360641\n",
      "CM Train = \n",
      "[[1574  270]\n",
      " [ 106 2505]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.76       199\n",
      "           1       0.81      0.92      0.86       296\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.83      0.80      0.81       495\n",
      "weighted avg       0.82      0.82      0.82       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 82.22%\n",
      "AUC Test:  0.7994788129838382\n",
      "CM Test = \n",
      "[[136  63]\n",
      " [ 25 271]]\n",
      "--------------------------------------------------------\n",
      "Fold  9\n",
      "TRAIN : [   0    1    2 ... 4946 4948 4949] TEST : [   7   28   32   62   74   75   78   79   83  103  110  115  116  120\n",
      "  123  127  131  150  165  181  183  186  212  213  222  225  236  243\n",
      "  247  266  284  324  337  363  373  395  397  401  403  417  424  445\n",
      "  448  450  464  471  510  523  540  571  592  611  612  614  617  625\n",
      "  626  627  645  656  662  673  697  699  742  747  753  761  765  777\n",
      "  790  798  808  824  833  858  885  901  911  920  922  947  968 1004\n",
      " 1024 1031 1064 1072 1075 1092 1102 1107 1124 1125 1130 1133 1153 1169\n",
      " 1178 1186 1189 1201 1218 1227 1233 1289 1291 1297 1307 1312 1320 1321\n",
      " 1344 1348 1360 1365 1383 1402 1407 1408 1409 1415 1440 1442 1443 1481\n",
      " 1498 1500 1502 1508 1510 1517 1527 1546 1576 1584 1595 1613 1614 1616\n",
      " 1622 1623 1629 1630 1631 1638 1655 1659 1674 1681 1685 1704 1711 1729\n",
      " 1745 1776 1781 1782 1787 1796 1797 1799 1807 1809 1821 1833 1842 1873\n",
      " 1874 1882 1890 1904 1909 1919 1932 1937 1938 1946 1970 1973 1984 2002\n",
      " 2015 2022 2032 2045 2056 2068 2097 2098 2122 2127 2129 2138 2153 2159\n",
      " 2167 2179 2182 2186 2199 2206 2227 2236 2253 2264 2273 2276 2283 2286\n",
      " 2309 2314 2317 2321 2333 2341 2349 2352 2354 2376 2380 2386 2392 2414\n",
      " 2422 2428 2437 2442 2444 2458 2469 2474 2479 2489 2495 2499 2503 2508\n",
      " 2511 2520 2524 2532 2538 2541 2544 2555 2576 2581 2589 2593 2598 2609\n",
      " 2614 2633 2634 2652 2684 2687 2691 2695 2710 2712 2716 2726 2733 2739\n",
      " 2742 2789 2800 2809 2819 2820 2822 2827 2845 2870 2874 2919 2927 2960\n",
      " 2963 2991 3017 3047 3062 3070 3078 3087 3092 3096 3102 3105 3109 3113\n",
      " 3115 3134 3137 3142 3143 3148 3153 3163 3189 3190 3215 3216 3230 3232\n",
      " 3246 3252 3267 3268 3271 3272 3277 3280 3285 3293 3306 3308 3316 3329\n",
      " 3330 3336 3356 3366 3372 3383 3384 3388 3393 3399 3404 3430 3437 3444\n",
      " 3454 3458 3467 3478 3485 3505 3511 3525 3543 3549 3557 3590 3593 3596\n",
      " 3604 3632 3641 3657 3661 3676 3685 3702 3716 3718 3728 3730 3747 3748\n",
      " 3749 3752 3765 3792 3794 3796 3797 3799 3800 3802 3806 3825 3841 3851\n",
      " 3874 3877 3952 3958 3962 3966 3971 3973 3980 3995 3997 4006 4038 4039\n",
      " 4045 4057 4060 4066 4076 4078 4087 4091 4094 4101 4108 4126 4142 4147\n",
      " 4162 4185 4186 4189 4191 4192 4201 4204 4212 4214 4218 4230 4242 4258\n",
      " 4260 4263 4278 4289 4301 4313 4332 4360 4374 4375 4376 4377 4381 4384\n",
      " 4390 4402 4407 4421 4430 4455 4460 4468 4479 4485 4499 4504 4508 4518\n",
      " 4529 4557 4562 4573 4577 4578 4591 4596 4597 4599 4606 4627 4636 4656\n",
      " 4665 4672 4675 4684 4697 4698 4710 4713 4715 4718 4733 4737 4740 4744\n",
      " 4804 4805 4809 4813 4818 4828 4830 4855 4871 4897 4900 4907 4915 4924\n",
      " 4927 4936 4941 4944 4947]\n",
      "[array([[0.49543017, 0.50456983],\n",
      "       [0.12525682, 0.87474318],\n",
      "       [0.33491004, 0.66508996],\n",
      "       ...,\n",
      "       [0.41010101, 0.58989899],\n",
      "       [0.2164016 , 0.7835984 ],\n",
      "       [0.85448019, 0.14551981]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1827\n",
      "           1       0.91      0.96      0.93      2628\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.92      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.96%\n",
      "AUC Train:  0.9099495017657512\n",
      "CM Train = \n",
      "[[1564  263]\n",
      " [  95 2533]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73       216\n",
      "           1       0.78      0.87      0.82       279\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.79      0.77      0.78       495\n",
      "weighted avg       0.79      0.79      0.78       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 78.59%\n",
      "AUC Test:  0.7734468339307049\n",
      "CM Test = \n",
      "[[146  70]\n",
      " [ 36 243]]\n",
      "--------------------------------------------------------\n",
      "Fold  10\n",
      "TRAIN : [   1    2    3 ... 4947 4948 4949] TEST : [   0   21   24   25   63   93   94   99  100  112  126  136  146  151\n",
      "  153  160  164  168  174  180  197  199  201  207  209  216  237  256\n",
      "  275  280  281  292  307  329  334  343  350  375  387  400  404  423\n",
      "  430  433  437  447  449  460  469  497  504  508  525  537  544  550\n",
      "  560  573  577  586  591  595  604  605  606  623  637  647  650  659\n",
      "  664  671  691  696  698  705  709  714  730  732  736  738  739  741\n",
      "  755  756  770  797  802  804  807  816  821  827  830  837  845  848\n",
      "  851  860  869  894  902  903  908  928  931  941  945  952  956  967\n",
      "  973 1006 1020 1028 1033 1040 1053 1071 1090 1111 1131 1134 1152 1159\n",
      " 1162 1167 1179 1198 1204 1207 1208 1209 1219 1221 1241 1243 1253 1305\n",
      " 1308 1331 1337 1353 1384 1392 1400 1429 1434 1438 1447 1468 1469 1472\n",
      " 1479 1483 1488 1532 1552 1561 1562 1582 1589 1605 1608 1634 1641 1645\n",
      " 1653 1671 1672 1684 1690 1701 1707 1720 1731 1734 1740 1747 1769 1777\n",
      " 1792 1795 1805 1823 1838 1847 1849 1862 1863 1868 1871 1896 1908 1910\n",
      " 1913 1924 1954 1956 1963 1967 1971 1975 1987 2003 2008 2021 2023 2040\n",
      " 2046 2051 2059 2105 2107 2120 2121 2135 2163 2173 2176 2187 2195 2197\n",
      " 2221 2222 2237 2251 2257 2261 2269 2274 2282 2292 2296 2304 2322 2335\n",
      " 2344 2353 2371 2375 2387 2389 2391 2405 2418 2431 2435 2446 2463 2467\n",
      " 2492 2496 2502 2536 2546 2547 2562 2595 2599 2603 2607 2610 2646 2659\n",
      " 2660 2665 2671 2679 2681 2683 2685 2711 2721 2723 2732 2745 2750 2757\n",
      " 2763 2766 2767 2775 2786 2787 2798 2811 2813 2850 2852 2860 2867 2881\n",
      " 2893 2897 2903 2904 2908 2930 2934 2937 2956 2957 2965 2977 2987 2989\n",
      " 2995 2997 2999 3024 3026 3057 3085 3091 3107 3114 3116 3123 3125 3128\n",
      " 3146 3165 3186 3187 3191 3204 3205 3208 3219 3221 3224 3264 3273 3279\n",
      " 3290 3291 3292 3298 3299 3310 3331 3337 3361 3395 3396 3398 3413 3418\n",
      " 3419 3421 3441 3445 3451 3455 3463 3465 3466 3468 3486 3510 3513 3516\n",
      " 3531 3533 3547 3560 3591 3611 3612 3622 3623 3642 3665 3674 3678 3686\n",
      " 3695 3715 3717 3729 3734 3745 3751 3762 3778 3781 3793 3808 3811 3821\n",
      " 3854 3860 3868 3886 3893 3898 3912 3918 3922 3928 3929 3942 3945 3968\n",
      " 3969 3988 3999 4009 4011 4040 4043 4047 4051 4071 4075 4089 4099 4103\n",
      " 4122 4163 4180 4182 4187 4226 4232 4259 4262 4272 4297 4305 4317 4333\n",
      " 4342 4353 4369 4370 4373 4378 4387 4393 4403 4417 4419 4420 4423 4444\n",
      " 4461 4464 4469 4484 4496 4503 4515 4516 4524 4525 4566 4605 4651 4652\n",
      " 4671 4677 4680 4687 4699 4703 4708 4711 4735 4746 4752 4763 4777 4783\n",
      " 4786 4827 4837 4851 4857 4859 4864 4865 4867 4870 4887 4893 4908 4918\n",
      " 4919 4921 4928 4931 4935]\n",
      "[array([[0.08785872, 0.91214128],\n",
      "       [0.37481418, 0.62518582],\n",
      "       [0.67538044, 0.32461956],\n",
      "       ...,\n",
      "       [0.7618786 , 0.2381214 ],\n",
      "       [0.2202634 , 0.7797366 ],\n",
      "       [0.85347833, 0.14652167]])]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1832\n",
      "           1       0.90      0.96      0.93      2623\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.65%\n",
      "AUC Train:  0.9060436148481604\n",
      "CM Train = \n",
      "[[1552  280]\n",
      " [  92 2531]]\n",
      "----- Evaluation on Test Data -----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74       211\n",
      "           1       0.79      0.86      0.82       284\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.79      0.78      0.78       495\n",
      "weighted avg       0.79      0.79      0.79       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 78.99%\n",
      "AUC Test:  0.7785278018823845\n",
      "CM Test = \n",
      "[[148  63]\n",
      " [ 41 243]]\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#K FOLD\n",
    "x = feature_tfidf\n",
    "y = df['sentiment']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1,\n",
    "random_state = 0)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "skf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "skf.get_n_splits(x, y)\n",
    "i = 1\n",
    "for train_index, test_index in skf.split(x, y) :\n",
    "  print(\"Fold \",i)\n",
    "  print(\"TRAIN :\",train_index,\"TEST :\",test_index)\n",
    "  x_train,x_test=x.loc[train_index] ,x.loc[test_index]\n",
    "  y_train, y_test=y[train_index], y[test_index]\n",
    "  i+=1\n",
    "  modellin = MultinomialNB()\n",
    "  clf_lin = modellin.fit(x_train, y_train)\n",
    "  \n",
    "  probasbaru = [MultinomialNB().fit(x_train, y_train).predict_proba(x_train)]\n",
    "  print(probasbaru)\n",
    "    \n",
    "  pred_labels_tr = modellin.predict(x_train)\n",
    "  pred_labels_te = modellin.predict(x_test)\n",
    "  cm_train = confusion_matrix(y_train, pred_labels_tr)\n",
    "  cm_test = confusion_matrix(y_test, pred_labels_te)\n",
    "  print('----- Evaluation on Training Data -----')\n",
    "  score_tr = modellin.score(x_train, y_train)\n",
    "\n",
    "  print(classification_report(y_train, pred_labels_tr))\n",
    "  print('--------------------------------------------------------')\n",
    "  print(\"Accuracy Train = {:.2f}%\".format(score_tr*100))\n",
    "  print(\"AUC Train: \", roc_auc_score(y_train, pred_labels_tr))\n",
    " \n",
    "  print(\"CM Train = \")\n",
    "  print(cm_train)\n",
    "  print('----- Evaluation on Test Data -----')\n",
    "  score_te = modellin.score(x_test, y_test)\n",
    "  print(classification_report(y_test, pred_labels_te))\n",
    "  print('--------------------------------------------------------')\n",
    "  print(\"Accuracy Test = {:.2f}%\".format(score_te*100))\n",
    "  print(\"AUC Test: \", roc_auc_score(y_test,pred_labels_te))\n",
    "  print(\"CM Test = \")\n",
    "  print(cm_test)\n",
    "  print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [  29   31   39   42   44   49   72   98  113  124  125  130  134  138\n",
      "  142  148  154  158  159  192  202  214  218  241  245  282  291  298\n",
      "  302  304  308  311  314  333  347  348  349  352  376  380  381  394\n",
      "  398  402  405  446  452  453  463  470  483  487  489  491  495  499\n",
      "  500  502  530  531  533  534  541  556  562  567  575  578  582  599\n",
      "  601  608  619  624  636  639  651  661  675  678  704  716  727  731\n",
      "  735  751  771  776  780  806  825  831  866  872  873  878  882  883\n",
      "  896  898  906  910  933  938  939  942  965  976  977  991 1001 1002\n",
      " 1003 1012 1013 1042 1043 1066 1085 1087 1091 1108 1109 1114 1115 1116\n",
      " 1118 1141 1176 1185 1202 1220 1239 1245 1246 1250 1262 1271 1275 1338\n",
      " 1349 1351 1358 1364 1368 1376 1389 1399 1422 1428 1430 1433 1437 1448\n",
      " 1457 1461 1474 1480 1482 1499 1509 1511 1514 1529 1545 1551 1556 1559\n",
      " 1564 1586 1606 1632 1642 1643 1651 1662 1670 1680 1688 1691 1695 1696\n",
      " 1702 1721 1742 1746 1749 1752 1760 1763 1772 1778 1783 1784 1793 1803\n",
      " 1819 1824 1855 1861 1865 1867 1869 1877 1891 1892 1894 1906 1916 1951\n",
      " 1953 1958 1969 1995 2006 2013 2017 2047 2066 2070 2081 2087 2091 2100\n",
      " 2103 2104 2106 2111 2160 2164 2165 2166 2175 2189 2200 2216 2250 2299\n",
      " 2311 2324 2332 2337 2345 2346 2351 2373 2381 2383 2384 2385 2394 2396\n",
      " 2423 2445 2447 2448 2450 2451 2459 2466 2493 2505 2518 2526 2533 2552\n",
      " 2585 2591 2612 2626 2635 2648 2651 2661 2669 2689 2692 2707 2708 2720\n",
      " 2728 2747 2752 2764 2772 2781 2790 2797 2802 2810 2814 2838 2855 2857\n",
      " 2869 2878 2905 2913 2920 2924 2952 2954 2964 2969 2982 3008 3010 3022\n",
      " 3031 3034 3035 3053 3054 3119 3133 3138 3160 3173 3188 3209 3238 3243\n",
      " 3254 3256 3258 3269 3275 3286 3288 3294 3302 3305 3317 3318 3332 3354\n",
      " 3355 3360 3375 3377 3386 3411 3414 3422 3461 3475 3480 3489 3491 3530\n",
      " 3538 3552 3554 3556 3561 3577 3581 3585 3587 3592 3595 3606 3638 3640\n",
      " 3649 3654 3714 3726 3736 3746 3760 3767 3771 3790 3807 3817 3826 3840\n",
      " 3844 3857 3862 3866 3867 3882 3901 3909 3934 3940 3946 3967 3970 3974\n",
      " 3979 3985 4000 4005 4007 4013 4019 4025 4037 4042 4070 4085 4095 4102\n",
      " 4105 4121 4127 4138 4149 4152 4160 4169 4174 4176 4195 4207 4213 4225\n",
      " 4234 4238 4246 4249 4251 4253 4266 4276 4299 4307 4308 4314 4318 4335\n",
      " 4345 4349 4351 4361 4397 4409 4425 4443 4449 4451 4457 4480 4481 4491\n",
      " 4520 4531 4532 4533 4547 4548 4549 4555 4561 4563 4590 4594 4610 4622\n",
      " 4645 4646 4654 4660 4668 4670 4688 4690 4694 4705 4714 4725 4729 4736\n",
      " 4738 4766 4775 4788 4789 4808 4820 4822 4831 4839 4849 4879 4881 4904\n",
      " 4905 4926 4932 4937 4943]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89      1842\n",
      "           1       0.91      0.96      0.93      2613\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.65%\n",
      "AUC Train:  0.9079131403867656\n",
      "CM Train = \n",
      "[[1581  261]\n",
      " [ 111 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77       201\n",
      "           1       0.82      0.91      0.86       294\n",
      "\n",
      "    accuracy                           0.83       495\n",
      "   macro avg       0.83      0.81      0.82       495\n",
      "weighted avg       0.83      0.83      0.83       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 83.03%\n",
      "AUC Test:  0.8115037059599959\n",
      "CM Test = \n",
      "[[143  58]\n",
      " [ 26 268]]\n",
      "--------------------------------------------------------\n",
      "Fold  2\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   9   12   22   30   33   34   45   57   70   87   95  104  117  122\n",
      "  135  156  161  162  167  170  173  189  195  217  220  223  224  246\n",
      "  252  253  263  269  271  294  326  378  379  383  396  406  410  415\n",
      "  472  481  496  507  514  517  520  521  526  528  538  543  545  548\n",
      "  559  584  628  629  630  634  641  660  666  668  684  720  728  773\n",
      "  775  788  799  812  817  829  842  843  844  847  849  852  854  861\n",
      "  862  864  867  871  888  891  895  918  949  962  971  979 1005 1011\n",
      " 1014 1022 1051 1065 1069 1082 1084 1098 1104 1119 1122 1139 1160 1161\n",
      " 1172 1177 1203 1224 1237 1256 1259 1261 1272 1277 1281 1290 1299 1319\n",
      " 1326 1327 1328 1329 1330 1332 1343 1362 1367 1380 1385 1387 1391 1393\n",
      " 1411 1412 1418 1419 1420 1423 1431 1450 1460 1475 1478 1487 1495 1497\n",
      " 1507 1515 1522 1525 1526 1531 1533 1536 1547 1563 1567 1580 1581 1590\n",
      " 1615 1620 1625 1652 1658 1675 1687 1692 1697 1700 1726 1741 1755 1765\n",
      " 1767 1774 1790 1791 1794 1834 1836 1872 1879 1888 1902 1926 1934 1939\n",
      " 1940 1965 1982 1986 1990 1996 1999 2012 2030 2033 2038 2048 2058 2063\n",
      " 2071 2075 2118 2124 2137 2150 2154 2171 2177 2201 2203 2212 2215 2219\n",
      " 2223 2231 2239 2260 2265 2290 2308 2315 2323 2339 2399 2401 2421 2436\n",
      " 2452 2455 2475 2478 2487 2491 2498 2500 2509 2527 2528 2539 2553 2579\n",
      " 2611 2617 2618 2619 2639 2650 2670 2672 2693 2700 2701 2706 2714 2719\n",
      " 2730 2734 2740 2744 2770 2779 2795 2817 2818 2829 2831 2832 2841 2846\n",
      " 2849 2864 2865 2872 2876 2882 2888 2899 2911 2915 2917 2933 2943 2949\n",
      " 2958 2959 2971 2981 2983 2992 3006 3011 3039 3040 3046 3068 3083 3086\n",
      " 3124 3127 3149 3162 3169 3196 3210 3212 3217 3220 3234 3244 3255 3260\n",
      " 3270 3276 3287 3289 3303 3343 3348 3371 3373 3408 3447 3452 3471 3473\n",
      " 3474 3503 3506 3508 3512 3514 3515 3524 3536 3539 3542 3546 3563 3567\n",
      " 3568 3575 3578 3579 3589 3601 3609 3615 3616 3617 3626 3644 3647 3658\n",
      " 3669 3670 3679 3680 3687 3698 3703 3704 3705 3709 3710 3712 3766 3772\n",
      " 3773 3776 3785 3786 3791 3805 3824 3853 3855 3859 3861 3880 3884 3890\n",
      " 3891 3899 3908 3913 3933 3948 3964 3984 3986 3994 3996 4001 4004 4010\n",
      " 4021 4023 4028 4030 4036 4041 4056 4062 4068 4069 4080 4083 4104 4112\n",
      " 4113 4123 4124 4130 4136 4154 4155 4158 4190 4237 4243 4252 4270 4311\n",
      " 4336 4338 4371 4391 4406 4422 4424 4440 4467 4473 4475 4497 4513 4519\n",
      " 4535 4537 4540 4541 4543 4556 4558 4572 4576 4581 4587 4589 4593 4601\n",
      " 4615 4618 4634 4637 4649 4659 4667 4689 4702 4724 4742 4747 4753 4758\n",
      " 4784 4793 4794 4814 4821 4829 4847 4861 4873 4880 4883 4885 4888 4892\n",
      " 4901 4903 4910 4912 4939]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1846\n",
      "           1       0.90      0.96      0.93      2609\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.67%\n",
      "AUC Train:  0.9079881001965444\n",
      "CM Train = \n",
      "[[1582  264]\n",
      " [ 107 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       197\n",
      "           1       0.85      0.90      0.88       298\n",
      "\n",
      "    accuracy                           0.85       495\n",
      "   macro avg       0.85      0.83      0.84       495\n",
      "weighted avg       0.85      0.85      0.85       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 84.85%\n",
      "AUC Test:  0.8345910128436616\n",
      "CM Test = \n",
      "[[151  46]\n",
      " [ 29 269]]\n",
      "--------------------------------------------------------\n",
      "Fold  3\n",
      "TRAIN : [   0    2    3 ... 4947 4948 4949] TEST : [   1   23   36   37   53   61   85   88  182  185  203  206  221  227\n",
      "  230  248  276  283  286  289  295  325  345  382  384  408  429  457\n",
      "  462  465  467  480  482  485  501  516  527  536  546  553  555  569\n",
      "  576  581  613  615  620  621  622  638  648  663  667  680  683  685\n",
      "  687  690  692  706  708  712  748  768  787  794  803  809  836  841\n",
      "  857  900  917  925  927  980  982  985  995 1009 1021 1046 1047 1068\n",
      " 1073 1077 1095 1127 1163 1170 1196 1223 1230 1232 1248 1267 1273 1280\n",
      " 1288 1298 1303 1309 1324 1357 1359 1363 1366 1370 1371 1377 1379 1390\n",
      " 1410 1414 1432 1441 1452 1465 1470 1471 1489 1490 1491 1505 1521 1523\n",
      " 1530 1540 1544 1569 1596 1654 1657 1666 1669 1698 1705 1706 1712 1715\n",
      " 1718 1722 1736 1738 1750 1754 1757 1759 1761 1766 1789 1804 1813 1814\n",
      " 1815 1828 1835 1850 1852 1870 1887 1889 1900 1907 1922 1928 1933 1957\n",
      " 1960 1972 1974 1989 1991 1992 2009 2011 2027 2034 2044 2052 2062 2065\n",
      " 2067 2069 2072 2078 2088 2102 2108 2112 2125 2149 2152 2162 2184 2188\n",
      " 2193 2194 2196 2204 2214 2217 2232 2240 2243 2255 2263 2270 2272 2275\n",
      " 2277 2284 2285 2301 2303 2307 2318 2327 2340 2355 2358 2359 2367 2370\n",
      " 2374 2382 2404 2433 2440 2460 2473 2481 2483 2494 2513 2531 2534 2571\n",
      " 2574 2586 2594 2602 2605 2606 2620 2644 2647 2649 2658 2663 2664 2676\n",
      " 2678 2686 2717 2729 2753 2769 2771 2803 2807 2828 2839 2858 2868 2886\n",
      " 2889 2901 2906 2922 2931 2938 2939 2951 2967 2974 2975 2976 2985 2996\n",
      " 3001 3005 3014 3021 3025 3037 3044 3045 3051 3058 3059 3061 3063 3072\n",
      " 3073 3076 3079 3090 3095 3097 3110 3120 3122 3131 3144 3145 3151 3152\n",
      " 3154 3156 3161 3174 3183 3184 3197 3200 3201 3202 3213 3225 3228 3233\n",
      " 3245 3262 3284 3297 3301 3312 3315 3327 3328 3334 3340 3349 3350 3351\n",
      " 3353 3368 3382 3389 3397 3425 3426 3427 3439 3456 3472 3477 3484 3488\n",
      " 3497 3498 3504 3518 3522 3529 3532 3558 3565 3569 3594 3597 3600 3602\n",
      " 3625 3630 3631 3636 3646 3651 3662 3664 3671 3677 3684 3707 3713 3741\n",
      " 3754 3755 3763 3774 3798 3804 3809 3819 3873 3881 3907 3911 3916 3930\n",
      " 3959 3977 3987 4002 4046 4050 4088 4092 4096 4098 4106 4115 4118 4120\n",
      " 4131 4133 4137 4140 4146 4151 4161 4167 4171 4172 4183 4200 4208 4216\n",
      " 4217 4228 4233 4244 4245 4264 4267 4274 4277 4279 4284 4293 4295 4300\n",
      " 4315 4316 4322 4323 4334 4337 4347 4348 4357 4362 4363 4364 4365 4368\n",
      " 4372 4380 4392 4399 4418 4426 4434 4446 4453 4474 4486 4487 4495 4500\n",
      " 4505 4527 4528 4534 4554 4564 4585 4588 4598 4628 4640 4641 4658 4669\n",
      " 4704 4712 4734 4741 4749 4756 4771 4773 4790 4797 4799 4806 4817 4844\n",
      " 4862 4902 4913 4929 4930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1851\n",
      "           1       0.91      0.96      0.93      2604\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.92      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 92.01%\n",
      "AUC Train:  0.9118812971939442\n",
      "CM Train = \n",
      "[[1598  253]\n",
      " [ 103 2501]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73       192\n",
      "           1       0.81      0.89      0.85       303\n",
      "\n",
      "    accuracy                           0.80       495\n",
      "   macro avg       0.80      0.78      0.79       495\n",
      "weighted avg       0.80      0.80      0.80       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 80.40%\n",
      "AUC Test:  0.778877887788779\n",
      "CM Test = \n",
      "[[128  64]\n",
      " [ 33 270]]\n",
      "--------------------------------------------------------\n",
      "Fold  4\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   3    4   10   14   15   17   50   64   66   71   86   92   97  109\n",
      "  118  132  133  137  144  149  169  177  188  190  191  196  200  219\n",
      "  226  229  234  242  244  249  257  261  285  288  290  296  299  305\n",
      "  306  316  317  321  322  332  338  346  368  386  388  389  390  399\n",
      "  409  418  421  422  426  436  440  443  444  451  461  473  509  535\n",
      "  558  565  566  570  572  579  587  589  590  596  598  607  616  635\n",
      "  643  654  682  688  695  725  729  743  749  758  832  834  835  840\n",
      "  868  879  880  897  899  905  914  929  934  935  944  951  953  958\n",
      "  959  961  983  988  989  996  998 1018 1034 1056 1059 1062 1070 1093\n",
      " 1120 1129 1144 1148 1150 1174 1180 1182 1183 1190 1191 1197 1206 1240\n",
      " 1242 1266 1269 1276 1282 1283 1284 1285 1287 1292 1300 1334 1336 1342\n",
      " 1373 1382 1386 1404 1427 1436 1445 1458 1464 1473 1494 1496 1503 1504\n",
      " 1513 1519 1542 1566 1571 1573 1574 1577 1593 1601 1621 1640 1644 1649\n",
      " 1667 1708 1744 1768 1770 1771 1800 1812 1826 1829 1830 1831 1837 1839\n",
      " 1853 1875 1881 1895 1931 1936 1941 1949 1961 1977 1979 1997 2016 2024\n",
      " 2036 2049 2060 2076 2089 2140 2148 2172 2211 2224 2234 2242 2244 2247\n",
      " 2278 2293 2294 2300 2306 2338 2347 2368 2377 2379 2397 2406 2425 2443\n",
      " 2464 2465 2470 2471 2477 2484 2490 2497 2501 2510 2519 2525 2530 2540\n",
      " 2543 2549 2566 2575 2577 2580 2601 2604 2616 2625 2630 2631 2640 2645\n",
      " 2655 2657 2667 2682 2696 2702 2703 2722 2724 2727 2736 2749 2755 2784\n",
      " 2794 2796 2804 2806 2812 2815 2816 2823 2825 2826 2830 2842 2843 2854\n",
      " 2885 2898 2921 2940 2994 3007 3012 3019 3027 3029 3036 3041 3050 3052\n",
      " 3055 3060 3065 3077 3080 3088 3098 3100 3111 3132 3139 3170 3179 3226\n",
      " 3229 3231 3236 3240 3253 3263 3274 3307 3311 3320 3322 3324 3338 3346\n",
      " 3390 3391 3392 3400 3410 3412 3429 3431 3432 3435 3440 3449 3453 3460\n",
      " 3493 3495 3520 3521 3535 3537 3550 3553 3564 3571 3583 3586 3598 3633\n",
      " 3655 3660 3663 3666 3672 3673 3682 3706 3732 3733 3740 3764 3783 3803\n",
      " 3822 3828 3838 3842 3843 3848 3849 3887 3889 3892 3895 3897 3900 3924\n",
      " 3932 3953 3957 3992 4003 4027 4031 4035 4044 4053 4079 4107 4109 4111\n",
      " 4114 4125 4134 4139 4141 4156 4173 4175 4178 4194 4209 4222 4235 4239\n",
      " 4240 4248 4254 4269 4298 4302 4304 4312 4340 4341 4385 4388 4394 4396\n",
      " 4400 4408 4412 4413 4432 4438 4462 4463 4466 4471 4478 4482 4488 4507\n",
      " 4512 4514 4544 4546 4560 4568 4570 4579 4623 4650 4657 4661 4663 4678\n",
      " 4681 4682 4685 4686 4706 4707 4722 4727 4731 4739 4757 4762 4769 4772\n",
      " 4776 4785 4796 4802 4811 4816 4826 4833 4834 4835 4841 4853 4868 4875\n",
      " 4877 4886 4911 4923 4934]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1844\n",
      "           1       0.91      0.96      0.93      2611\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.83%\n",
      "AUC Train:  0.9099836043237729\n",
      "CM Train = \n",
      "[[1589  255]\n",
      " [ 109 2502]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.69      0.75       199\n",
      "           1       0.81      0.90      0.85       296\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.82      0.80      0.80       495\n",
      "weighted avg       0.82      0.82      0.81       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 81.62%\n",
      "AUC Test:  0.7960579926660329\n",
      "CM Test = \n",
      "[[138  61]\n",
      " [ 30 266]]\n",
      "--------------------------------------------------------\n",
      "Fold  5\n",
      "TRAIN : [   0    1    3 ... 4947 4948 4949] TEST : [   2    5   40   51   68   69   76   82  105  121  141  163  175  176\n",
      "  179  204  211  228  232  235  238  240  259  264  272  277  297  300\n",
      "  313  320  323  330  351  353  356  361  365  366  369  385  411  413\n",
      "  414  419  425  427  454  458  488  493  503  515  519  529  547  564\n",
      "  574  600  618  652  655  657  670  674  677  681  686  694  701  702\n",
      "  703  710  711  713  719  722  744  745  746  764  778  779  783  786\n",
      "  791  793  796  800  805  826  838  846  850  853  856  874  890  923\n",
      "  924  936  937  940  943  954  955  963  964  972  975  981  984  999\n",
      " 1015 1023 1032 1036 1037 1038 1044 1048 1052 1058 1074 1078 1079 1081\n",
      " 1094 1100 1101 1110 1112 1128 1137 1140 1149 1151 1157 1171 1184 1194\n",
      " 1195 1199 1214 1225 1235 1236 1254 1255 1268 1270 1310 1311 1313 1317\n",
      " 1318 1341 1347 1355 1388 1395 1397 1425 1446 1451 1462 1493 1501 1535\n",
      " 1548 1553 1554 1555 1560 1572 1583 1600 1602 1607 1618 1646 1647 1656\n",
      " 1660 1693 1699 1703 1710 1713 1719 1728 1732 1733 1739 1751 1762 1764\n",
      " 1775 1798 1811 1818 1825 1832 1856 1860 1878 1886 1898 1899 1911 1912\n",
      " 1914 1917 1921 1927 1943 1945 1947 1948 1952 1955 1994 2000 2004 2010\n",
      " 2019 2031 2039 2041 2042 2057 2085 2092 2094 2101 2110 2117 2131 2134\n",
      " 2139 2141 2143 2146 2155 2157 2161 2169 2174 2178 2183 2185 2228 2230\n",
      " 2254 2258 2281 2287 2310 2329 2343 2350 2357 2361 2364 2365 2369 2372\n",
      " 2378 2400 2407 2409 2412 2417 2439 2453 2457 2472 2480 2507 2517 2523\n",
      " 2537 2542 2545 2550 2565 2578 2590 2592 2600 2608 2666 2709 2718 2731\n",
      " 2758 2760 2762 2768 2776 2782 2788 2791 2793 2799 2808 2840 2848 2863\n",
      " 2866 2873 2879 2884 2892 2900 2902 2916 2923 2928 2942 2947 2948 2953\n",
      " 2961 2962 2966 2986 2998 3030 3038 3043 3082 3126 3129 3135 3171 3172\n",
      " 3180 3195 3199 3227 3239 3265 3304 3314 3335 3339 3341 3352 3362 3374\n",
      " 3380 3381 3403 3417 3433 3434 3442 3443 3448 3450 3457 3462 3464 3469\n",
      " 3502 3509 3528 3548 3559 3570 3573 3574 3580 3618 3634 3637 3652 3653\n",
      " 3675 3688 3691 3700 3701 3722 3731 3735 3757 3770 3777 3780 3784 3795\n",
      " 3814 3815 3839 3847 3858 3865 3883 3885 3903 3904 3921 3935 3956 3965\n",
      " 3982 4017 4058 4059 4064 4074 4086 4110 4135 4165 4199 4202 4205 4206\n",
      " 4211 4221 4229 4247 4250 4257 4261 4265 4268 4282 4286 4288 4291 4296\n",
      " 4321 4330 4339 4354 4379 4382 4414 4439 4448 4459 4489 4490 4493 4498\n",
      " 4502 4509 4511 4522 4552 4583 4595 4600 4614 4616 4619 4625 4626 4631\n",
      " 4633 4635 4638 4644 4695 4696 4709 4720 4726 4728 4745 4750 4751 4755\n",
      " 4768 4781 4782 4795 4812 4819 4823 4836 4843 4848 4852 4869 4889 4890\n",
      " 4894 4895 4898 4909 4940]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1835\n",
      "           1       0.90      0.96      0.93      2620\n",
      "\n",
      "    accuracy                           0.91      4455\n",
      "   macro avg       0.92      0.90      0.91      4455\n",
      "weighted avg       0.92      0.91      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.38%\n",
      "AUC Train:  0.9040216735653223\n",
      "CM Train = \n",
      "[[1557  278]\n",
      " [ 106 2514]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73       208\n",
      "           1       0.79      0.88      0.83       287\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.80      0.78      0.78       495\n",
      "weighted avg       0.79      0.79      0.79       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 79.39%\n",
      "AUC Test:  0.7779666979362101\n",
      "CM Test = \n",
      "[[141  67]\n",
      " [ 35 252]]\n",
      "--------------------------------------------------------\n",
      "Fold  6\n",
      "TRAIN : [   0    1    2 ... 4947 4948 4949] TEST : [   6    8   11   13   18   20   26   27   41   47   48   52   58   59\n",
      "   67   80   84   90  107  108  119  145  157  187  194  215  251  254\n",
      "  268  274  278  303  315  318  328  331  340  344  357  359  360  391\n",
      "  392  393  438  439  442  455  456  459  468  474  476  477  478  486\n",
      "  505  518  522  557  563  568  585  588  597  602  603  609  610  646\n",
      "  653  669  672  676  689  700  715  717  723  752  757  762  766  772\n",
      "  774  781  784  789  795  813  819  820  855  859  865  886  909  912\n",
      "  913  919  921  926  932  966  969  993  997 1017 1025 1027 1035 1041\n",
      " 1049 1055 1061 1063 1083 1086 1099 1103 1106 1117 1136 1138 1147 1158\n",
      " 1168 1173 1187 1210 1212 1213 1215 1217 1222 1231 1238 1244 1264 1278\n",
      " 1293 1296 1315 1346 1352 1354 1372 1374 1396 1403 1424 1426 1444 1449\n",
      " 1454 1463 1467 1476 1477 1485 1549 1550 1587 1592 1599 1603 1604 1609\n",
      " 1610 1612 1626 1633 1636 1648 1663 1673 1686 1694 1714 1717 1723 1724\n",
      " 1727 1735 1737 1748 1756 1780 1785 1806 1808 1810 1846 1854 1897 1905\n",
      " 1915 1918 1920 1923 1929 1930 1944 1950 1959 1962 1976 1978 1980 1983\n",
      " 2005 2025 2054 2074 2080 2095 2096 2115 2123 2126 2142 2145 2151 2180\n",
      " 2181 2192 2198 2205 2210 2226 2248 2252 2268 2271 2280 2312 2319 2331\n",
      " 2334 2362 2411 2415 2420 2427 2432 2438 2462 2476 2485 2486 2488 2535\n",
      " 2551 2554 2556 2558 2560 2570 2573 2584 2587 2613 2615 2621 2623 2627\n",
      " 2629 2636 2673 2688 2694 2713 2715 2735 2741 2743 2748 2751 2756 2759\n",
      " 2761 2777 2778 2805 2824 2835 2856 2875 2877 2895 2907 2909 2926 2929\n",
      " 2944 2946 2955 2972 2980 2984 3002 3009 3016 3023 3048 3056 3066 3067\n",
      " 3071 3074 3075 3081 3099 3103 3104 3108 3118 3140 3141 3150 3157 3166\n",
      " 3175 3177 3206 3207 3214 3222 3235 3237 3241 3251 3278 3281 3319 3321\n",
      " 3323 3325 3357 3359 3364 3365 3369 3376 3385 3405 3438 3446 3482 3487\n",
      " 3499 3500 3501 3507 3517 3526 3540 3551 3572 3603 3619 3628 3635 3639\n",
      " 3681 3693 3699 3739 3743 3744 3753 3756 3758 3761 3789 3810 3820 3827\n",
      " 3830 3831 3832 3836 3845 3852 3856 3863 3864 3872 3876 3878 3917 3927\n",
      " 3937 3941 3954 3960 3976 3978 3981 3989 3991 3993 4008 4012 4015 4016\n",
      " 4018 4020 4022 4029 4032 4033 4034 4054 4061 4067 4073 4077 4081 4082\n",
      " 4090 4129 4143 4148 4153 4166 4181 4188 4193 4196 4198 4219 4223 4231\n",
      " 4255 4271 4273 4283 4287 4327 4346 4350 4389 4405 4411 4431 4433 4435\n",
      " 4477 4483 4506 4523 4526 4569 4592 4607 4611 4612 4617 4630 4632 4643\n",
      " 4647 4648 4653 4655 4662 4666 4673 4691 4692 4693 4717 4719 4732 4754\n",
      " 4764 4770 4800 4801 4815 4824 4838 4842 4845 4854 4866 4874 4876 4878\n",
      " 4896 4914 4917 4945 4946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1832\n",
      "           1       0.91      0.96      0.93      2623\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.81%\n",
      "AUC Train:  0.9091886602726637\n",
      "CM Train = \n",
      "[[1574  258]\n",
      " [ 107 2516]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.64      0.74       211\n",
      "           1       0.78      0.92      0.84       284\n",
      "\n",
      "    accuracy                           0.80       495\n",
      "   macro avg       0.82      0.78      0.79       495\n",
      "weighted avg       0.81      0.80      0.80       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 80.20%\n",
      "AUC Test:  0.7817819237701088\n",
      "CM Test = \n",
      "[[136  75]\n",
      " [ 23 261]]\n",
      "--------------------------------------------------------\n",
      "Fold  7\n",
      "TRAIN : [   0    1    2 ... 4946 4947 4948] TEST : [  19   43   46   54   55   77   91  101  102  106  111  128  139  140\n",
      "  147  152  166  198  208  233  250  255  260  262  267  270  279  287\n",
      "  301  309  310  312  327  335  342  354  407  431  441  466  475  490\n",
      "  492  506  511  512  513  532  551  583  593  594  633  642  665  718\n",
      "  721  724  733  750  767  792  810  815  818  822  828  876  884  892\n",
      "  893  904  907  915  916  930  946  950  970  986  987  990 1000 1007\n",
      " 1010 1019 1029 1030 1039 1045 1054 1067 1088 1096 1097 1105 1126 1142\n",
      " 1145 1155 1165 1175 1188 1192 1193 1205 1211 1226 1247 1251 1252 1257\n",
      " 1258 1260 1263 1279 1286 1301 1302 1304 1314 1316 1322 1323 1335 1339\n",
      " 1345 1350 1369 1375 1381 1394 1416 1417 1453 1455 1486 1512 1524 1537\n",
      " 1538 1539 1541 1543 1557 1568 1570 1578 1588 1611 1617 1627 1628 1637\n",
      " 1639 1665 1677 1678 1679 1683 1709 1716 1725 1743 1753 1758 1773 1779\n",
      " 1786 1801 1817 1822 1827 1840 1841 1844 1845 1857 1859 1866 1880 1883\n",
      " 1884 1885 1901 1925 1942 1964 1966 1981 1993 2001 2014 2029 2037 2043\n",
      " 2053 2055 2064 2073 2079 2082 2084 2090 2109 2114 2128 2130 2132 2133\n",
      " 2144 2147 2158 2170 2190 2209 2213 2220 2233 2235 2241 2249 2288 2295\n",
      " 2297 2298 2302 2313 2326 2330 2342 2348 2390 2393 2403 2408 2410 2413\n",
      " 2416 2419 2424 2429 2430 2434 2441 2461 2468 2482 2506 2516 2521 2522\n",
      " 2559 2563 2564 2567 2569 2572 2583 2588 2597 2622 2628 2632 2642 2653\n",
      " 2662 2668 2674 2675 2677 2697 2699 2704 2705 2738 2774 2783 2801 2833\n",
      " 2837 2847 2853 2859 2871 2880 2887 2890 2891 2894 2896 2912 2918 2935\n",
      " 2941 2945 2950 2968 2970 2979 3000 3015 3028 3033 3064 3084 3089 3093\n",
      " 3106 3121 3130 3136 3147 3155 3158 3164 3167 3185 3194 3198 3211 3218\n",
      " 3223 3247 3249 3259 3261 3266 3282 3283 3295 3309 3326 3333 3342 3378\n",
      " 3379 3394 3407 3416 3420 3424 3428 3459 3479 3481 3490 3496 3519 3534\n",
      " 3562 3576 3582 3584 3588 3610 3621 3624 3629 3643 3648 3650 3659 3667\n",
      " 3668 3689 3694 3697 3711 3720 3723 3725 3738 3750 3759 3768 3787 3788\n",
      " 3801 3816 3823 3837 3869 3871 3879 3888 3894 3896 3902 3905 3906 3915\n",
      " 3919 3923 3925 3936 3939 3947 3961 3963 3972 3975 3983 3998 4014 4024\n",
      " 4049 4055 4065 4072 4084 4093 4100 4116 4132 4144 4145 4157 4159 4164\n",
      " 4179 4210 4227 4241 4281 4285 4290 4292 4294 4303 4309 4310 4319 4324\n",
      " 4328 4343 4355 4366 4367 4383 4398 4404 4429 4436 4441 4445 4450 4456\n",
      " 4458 4470 4492 4510 4517 4521 4530 4536 4539 4550 4551 4567 4571 4574\n",
      " 4575 4580 4582 4584 4586 4604 4608 4620 4621 4642 4679 4683 4716 4723\n",
      " 4748 4759 4765 4767 4778 4780 4787 4798 4807 4840 4850 4858 4863 4872\n",
      " 4916 4920 4925 4938 4949]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      1834\n",
      "           1       0.90      0.96      0.93      2621\n",
      "\n",
      "    accuracy                           0.91      4455\n",
      "   macro avg       0.92      0.90      0.91      4455\n",
      "weighted avg       0.91      0.91      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.36%\n",
      "AUC Train:  0.9039610444455631\n",
      "CM Train = \n",
      "[[1558  276]\n",
      " [ 109 2512]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77       209\n",
      "           1       0.80      0.92      0.86       286\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.83      0.80      0.81       495\n",
      "weighted avg       0.83      0.82      0.82       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 82.22%\n",
      "AUC Test:  0.8042878174457122\n",
      "CM Test = \n",
      "[[144  65]\n",
      " [ 23 263]]\n",
      "--------------------------------------------------------\n",
      "Fold  8\n",
      "TRAIN : [   0    1    2 ... 4946 4947 4949] TEST : [  16   35   38   56   60   65   73   81   89   96  114  129  143  155\n",
      "  171  172  178  184  193  205  210  231  239  258  265  273  293  319\n",
      "  336  339  341  355  358  362  364  367  370  371  372  374  377  412\n",
      "  416  420  428  432  434  435  479  484  494  498  524  539  542  549\n",
      "  552  554  561  580  631  632  640  644  649  658  679  693  707  726\n",
      "  734  737  740  754  759  760  763  769  782  785  801  811  814  823\n",
      "  839  863  870  875  877  881  887  889  948  957  960  974  978  992\n",
      "  994 1008 1016 1026 1050 1057 1060 1076 1080 1089 1113 1121 1123 1132\n",
      " 1135 1143 1146 1154 1156 1164 1166 1181 1200 1216 1228 1229 1234 1249\n",
      " 1265 1274 1294 1295 1306 1325 1333 1340 1356 1361 1378 1398 1401 1405\n",
      " 1406 1413 1421 1435 1439 1456 1459 1466 1484 1492 1506 1516 1518 1520\n",
      " 1528 1534 1558 1565 1575 1579 1585 1591 1594 1597 1598 1619 1624 1635\n",
      " 1650 1661 1664 1668 1676 1682 1689 1730 1788 1802 1816 1820 1843 1848\n",
      " 1851 1858 1864 1876 1893 1903 1935 1968 1985 1988 1998 2007 2018 2020\n",
      " 2026 2028 2035 2050 2061 2077 2083 2086 2093 2099 2113 2116 2119 2136\n",
      " 2156 2168 2191 2202 2207 2208 2218 2225 2229 2238 2245 2246 2256 2259\n",
      " 2262 2266 2267 2279 2289 2291 2305 2316 2320 2325 2328 2336 2356 2360\n",
      " 2363 2366 2388 2395 2398 2402 2426 2449 2454 2456 2504 2512 2514 2515\n",
      " 2529 2548 2557 2561 2568 2582 2596 2624 2637 2638 2641 2643 2654 2656\n",
      " 2680 2690 2698 2725 2737 2746 2754 2765 2773 2780 2785 2792 2821 2834\n",
      " 2836 2844 2851 2861 2862 2883 2910 2914 2925 2932 2936 2973 2978 2988\n",
      " 2990 2993 3003 3004 3013 3018 3020 3032 3042 3049 3069 3094 3101 3112\n",
      " 3117 3159 3168 3176 3178 3181 3182 3192 3193 3203 3242 3248 3250 3257\n",
      " 3296 3300 3313 3344 3345 3347 3358 3363 3367 3370 3387 3401 3402 3406\n",
      " 3409 3415 3423 3436 3470 3476 3483 3492 3494 3523 3527 3541 3544 3545\n",
      " 3555 3566 3599 3605 3607 3608 3613 3614 3620 3627 3645 3656 3683 3690\n",
      " 3692 3696 3708 3719 3721 3724 3727 3737 3742 3769 3775 3779 3782 3812\n",
      " 3813 3818 3829 3833 3834 3835 3846 3850 3870 3875 3910 3914 3920 3926\n",
      " 3931 3938 3943 3944 3949 3950 3951 3955 3990 4026 4048 4052 4063 4097\n",
      " 4117 4119 4128 4150 4168 4170 4177 4184 4197 4203 4215 4220 4224 4236\n",
      " 4256 4275 4280 4306 4320 4325 4326 4329 4331 4344 4352 4356 4358 4359\n",
      " 4386 4395 4401 4410 4415 4416 4427 4428 4437 4442 4447 4452 4454 4465\n",
      " 4472 4476 4494 4501 4538 4542 4545 4553 4559 4565 4602 4603 4609 4613\n",
      " 4624 4629 4639 4664 4674 4676 4700 4701 4721 4730 4743 4760 4761 4774\n",
      " 4779 4791 4792 4803 4810 4825 4832 4846 4856 4860 4882 4884 4891 4899\n",
      " 4906 4922 4933 4942 4948]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1844\n",
      "           1       0.90      0.96      0.93      2611\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.91      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.56%\n",
      "AUC Train:  0.9064908517360641\n",
      "CM Train = \n",
      "[[1574  270]\n",
      " [ 106 2505]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.68      0.76       199\n",
      "           1       0.81      0.92      0.86       296\n",
      "\n",
      "    accuracy                           0.82       495\n",
      "   macro avg       0.83      0.80      0.81       495\n",
      "weighted avg       0.82      0.82      0.82       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 82.22%\n",
      "AUC Test:  0.7994788129838382\n",
      "CM Test = \n",
      "[[136  63]\n",
      " [ 25 271]]\n",
      "--------------------------------------------------------\n",
      "Fold  9\n",
      "TRAIN : [   0    1    2 ... 4946 4948 4949] TEST : [   7   28   32   62   74   75   78   79   83  103  110  115  116  120\n",
      "  123  127  131  150  165  181  183  186  212  213  222  225  236  243\n",
      "  247  266  284  324  337  363  373  395  397  401  403  417  424  445\n",
      "  448  450  464  471  510  523  540  571  592  611  612  614  617  625\n",
      "  626  627  645  656  662  673  697  699  742  747  753  761  765  777\n",
      "  790  798  808  824  833  858  885  901  911  920  922  947  968 1004\n",
      " 1024 1031 1064 1072 1075 1092 1102 1107 1124 1125 1130 1133 1153 1169\n",
      " 1178 1186 1189 1201 1218 1227 1233 1289 1291 1297 1307 1312 1320 1321\n",
      " 1344 1348 1360 1365 1383 1402 1407 1408 1409 1415 1440 1442 1443 1481\n",
      " 1498 1500 1502 1508 1510 1517 1527 1546 1576 1584 1595 1613 1614 1616\n",
      " 1622 1623 1629 1630 1631 1638 1655 1659 1674 1681 1685 1704 1711 1729\n",
      " 1745 1776 1781 1782 1787 1796 1797 1799 1807 1809 1821 1833 1842 1873\n",
      " 1874 1882 1890 1904 1909 1919 1932 1937 1938 1946 1970 1973 1984 2002\n",
      " 2015 2022 2032 2045 2056 2068 2097 2098 2122 2127 2129 2138 2153 2159\n",
      " 2167 2179 2182 2186 2199 2206 2227 2236 2253 2264 2273 2276 2283 2286\n",
      " 2309 2314 2317 2321 2333 2341 2349 2352 2354 2376 2380 2386 2392 2414\n",
      " 2422 2428 2437 2442 2444 2458 2469 2474 2479 2489 2495 2499 2503 2508\n",
      " 2511 2520 2524 2532 2538 2541 2544 2555 2576 2581 2589 2593 2598 2609\n",
      " 2614 2633 2634 2652 2684 2687 2691 2695 2710 2712 2716 2726 2733 2739\n",
      " 2742 2789 2800 2809 2819 2820 2822 2827 2845 2870 2874 2919 2927 2960\n",
      " 2963 2991 3017 3047 3062 3070 3078 3087 3092 3096 3102 3105 3109 3113\n",
      " 3115 3134 3137 3142 3143 3148 3153 3163 3189 3190 3215 3216 3230 3232\n",
      " 3246 3252 3267 3268 3271 3272 3277 3280 3285 3293 3306 3308 3316 3329\n",
      " 3330 3336 3356 3366 3372 3383 3384 3388 3393 3399 3404 3430 3437 3444\n",
      " 3454 3458 3467 3478 3485 3505 3511 3525 3543 3549 3557 3590 3593 3596\n",
      " 3604 3632 3641 3657 3661 3676 3685 3702 3716 3718 3728 3730 3747 3748\n",
      " 3749 3752 3765 3792 3794 3796 3797 3799 3800 3802 3806 3825 3841 3851\n",
      " 3874 3877 3952 3958 3962 3966 3971 3973 3980 3995 3997 4006 4038 4039\n",
      " 4045 4057 4060 4066 4076 4078 4087 4091 4094 4101 4108 4126 4142 4147\n",
      " 4162 4185 4186 4189 4191 4192 4201 4204 4212 4214 4218 4230 4242 4258\n",
      " 4260 4263 4278 4289 4301 4313 4332 4360 4374 4375 4376 4377 4381 4384\n",
      " 4390 4402 4407 4421 4430 4455 4460 4468 4479 4485 4499 4504 4508 4518\n",
      " 4529 4557 4562 4573 4577 4578 4591 4596 4597 4599 4606 4627 4636 4656\n",
      " 4665 4672 4675 4684 4697 4698 4710 4713 4715 4718 4733 4737 4740 4744\n",
      " 4804 4805 4809 4813 4818 4828 4830 4855 4871 4897 4900 4907 4915 4924\n",
      " 4927 4936 4941 4944 4947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90      1827\n",
      "           1       0.91      0.96      0.93      2628\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.92      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.96%\n",
      "AUC Train:  0.9099495017657512\n",
      "CM Train = \n",
      "[[1564  263]\n",
      " [  95 2533]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.73       216\n",
      "           1       0.78      0.87      0.82       279\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.79      0.77      0.78       495\n",
      "weighted avg       0.79      0.79      0.78       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 78.59%\n",
      "AUC Test:  0.7734468339307049\n",
      "CM Test = \n",
      "[[146  70]\n",
      " [ 36 243]]\n",
      "--------------------------------------------------------\n",
      "Fold  10\n",
      "TRAIN : [   1    2    3 ... 4947 4948 4949] TEST : [   0   21   24   25   63   93   94   99  100  112  126  136  146  151\n",
      "  153  160  164  168  174  180  197  199  201  207  209  216  237  256\n",
      "  275  280  281  292  307  329  334  343  350  375  387  400  404  423\n",
      "  430  433  437  447  449  460  469  497  504  508  525  537  544  550\n",
      "  560  573  577  586  591  595  604  605  606  623  637  647  650  659\n",
      "  664  671  691  696  698  705  709  714  730  732  736  738  739  741\n",
      "  755  756  770  797  802  804  807  816  821  827  830  837  845  848\n",
      "  851  860  869  894  902  903  908  928  931  941  945  952  956  967\n",
      "  973 1006 1020 1028 1033 1040 1053 1071 1090 1111 1131 1134 1152 1159\n",
      " 1162 1167 1179 1198 1204 1207 1208 1209 1219 1221 1241 1243 1253 1305\n",
      " 1308 1331 1337 1353 1384 1392 1400 1429 1434 1438 1447 1468 1469 1472\n",
      " 1479 1483 1488 1532 1552 1561 1562 1582 1589 1605 1608 1634 1641 1645\n",
      " 1653 1671 1672 1684 1690 1701 1707 1720 1731 1734 1740 1747 1769 1777\n",
      " 1792 1795 1805 1823 1838 1847 1849 1862 1863 1868 1871 1896 1908 1910\n",
      " 1913 1924 1954 1956 1963 1967 1971 1975 1987 2003 2008 2021 2023 2040\n",
      " 2046 2051 2059 2105 2107 2120 2121 2135 2163 2173 2176 2187 2195 2197\n",
      " 2221 2222 2237 2251 2257 2261 2269 2274 2282 2292 2296 2304 2322 2335\n",
      " 2344 2353 2371 2375 2387 2389 2391 2405 2418 2431 2435 2446 2463 2467\n",
      " 2492 2496 2502 2536 2546 2547 2562 2595 2599 2603 2607 2610 2646 2659\n",
      " 2660 2665 2671 2679 2681 2683 2685 2711 2721 2723 2732 2745 2750 2757\n",
      " 2763 2766 2767 2775 2786 2787 2798 2811 2813 2850 2852 2860 2867 2881\n",
      " 2893 2897 2903 2904 2908 2930 2934 2937 2956 2957 2965 2977 2987 2989\n",
      " 2995 2997 2999 3024 3026 3057 3085 3091 3107 3114 3116 3123 3125 3128\n",
      " 3146 3165 3186 3187 3191 3204 3205 3208 3219 3221 3224 3264 3273 3279\n",
      " 3290 3291 3292 3298 3299 3310 3331 3337 3361 3395 3396 3398 3413 3418\n",
      " 3419 3421 3441 3445 3451 3455 3463 3465 3466 3468 3486 3510 3513 3516\n",
      " 3531 3533 3547 3560 3591 3611 3612 3622 3623 3642 3665 3674 3678 3686\n",
      " 3695 3715 3717 3729 3734 3745 3751 3762 3778 3781 3793 3808 3811 3821\n",
      " 3854 3860 3868 3886 3893 3898 3912 3918 3922 3928 3929 3942 3945 3968\n",
      " 3969 3988 3999 4009 4011 4040 4043 4047 4051 4071 4075 4089 4099 4103\n",
      " 4122 4163 4180 4182 4187 4226 4232 4259 4262 4272 4297 4305 4317 4333\n",
      " 4342 4353 4369 4370 4373 4378 4387 4393 4403 4417 4419 4420 4423 4444\n",
      " 4461 4464 4469 4484 4496 4503 4515 4516 4524 4525 4566 4605 4651 4652\n",
      " 4671 4677 4680 4687 4699 4703 4708 4711 4735 4746 4752 4763 4777 4783\n",
      " 4786 4827 4837 4851 4857 4859 4864 4865 4867 4870 4887 4893 4908 4918\n",
      " 4919 4921 4928 4931 4935]\n",
      "----- Evaluation on Training Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      1832\n",
      "           1       0.90      0.96      0.93      2623\n",
      "\n",
      "    accuracy                           0.92      4455\n",
      "   macro avg       0.92      0.91      0.91      4455\n",
      "weighted avg       0.92      0.92      0.92      4455\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Train = 91.65%\n",
      "AUC Train:  0.9060436148481604\n",
      "CM Train = \n",
      "[[1552  280]\n",
      " [  92 2531]]\n",
      "----- Evaluation on Test Data -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74       211\n",
      "           1       0.79      0.86      0.82       284\n",
      "\n",
      "    accuracy                           0.79       495\n",
      "   macro avg       0.79      0.78      0.78       495\n",
      "weighted avg       0.79      0.79      0.79       495\n",
      "\n",
      "--------------------------------------------------------\n",
      "Accuracy Test = 78.99%\n",
      "AUC Test:  0.7785278018823845\n",
      "CM Test = \n",
      "[[148  63]\n",
      " [ 41 243]]\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Klasifikasi NaÃ¯ve Bayes\n",
    "x = feature_tfidf\n",
    "y = df['sentiment']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1,\n",
    "random_state = 0)\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "kf.get_n_splits(x, y)\n",
    "i = 1\n",
    "for train_index, test_index in skf.split(x, y) :\n",
    "  print(\"Fold \",i)\n",
    "  print(\"TRAIN :\",train_index,\"TEST :\",test_index)\n",
    "  y_train, y_test=y[train_index], y[test_index]\n",
    "  i+=1\n",
    "  modellin = MultinomialNB()\n",
    "  x_train ,x_test=x.loc[train_index] ,x.loc[test_index]\n",
    "  clf_lin = modellin.fit(x_train, y_train)\n",
    "  \n",
    "  pred_labels_tr = modellin.predict(x_train)\n",
    "  pred_labels_te = modellin.predict(x_test)\n",
    "\n",
    "  cm_train = confusion_matrix(y_train, pred_labels_tr)\n",
    "  cm_test = confusion_matrix(y_test, pred_labels_te)\n",
    "\n",
    "  print('----- Evaluation on Training Data -----')\n",
    "  score_tr = modellin.score(x_train, y_train)\n",
    "\n",
    "  print(classification_report(y_train, pred_labels_tr))\n",
    "  print('--------------------------------------------------------')\n",
    "  print(\"Accuracy Train = {:.2f}%\".format(score_tr*100))\n",
    "  print(\"AUC Train: \", roc_auc_score(y_train, pred_labels_tr))\n",
    " \n",
    "  print(\"CM Train = \")\n",
    "  print(cm_train)\n",
    "  print('----- Evaluation on Test Data -----')\n",
    "  score_te = modellin.score(x_test, y_test)\n",
    "  print(classification_report(y_test, pred_labels_te))\n",
    "  print('--------------------------------------------------------')\n",
    "  print(\"Accuracy Test = {:.2f}%\".format(score_te*100))\n",
    "  print(\"AUC Test: \", roc_auc_score(y_test,pred_labels_te))\n",
    "  print(\"CM Test = \")\n",
    "  print(cm_test)\n",
    "  print('--------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJmgu0qBlwBLIQEaLaZtWX",
   "collapsed_sections": [],
   "mount_file_id": "16XfRwI4X-Kula8nhN6tDWFJaulIhpkAQ",
   "name": "Proyek Akhir Telegram.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
